# name       : innodb_split_buf_pool_mutex.patch
# introduced : 11 or before
# maintainer : Yasufumi
#
#!!! notice !!!
# Any small change to this file in the main branch
# should be done or reviewed by the maintainer!
--- a/storage/innodb_plugin/btr/btr0cur.c
+++ b/storage/innodb_plugin/btr/btr0cur.c
@@ -3853,7 +3853,8 @@
 
 	mtr_commit(mtr);
 
-	buf_pool_mutex_enter();
+	//buf_pool_mutex_enter();
+	mutex_enter(&LRU_list_mutex);
 	mutex_enter(&block->mutex);
 
 	/* Only free the block if it is still allocated to
@@ -3864,16 +3865,21 @@
 	    && buf_block_get_space(block) == space
 	    && buf_block_get_page_no(block) == page_no) {
 
-		if (!buf_LRU_free_block(&block->page, all)
-		    && all && block->page.zip.data) {
+		if (!buf_LRU_free_block(&block->page, all, TRUE)
+		    && all && block->page.zip.data
+		    /* Now, buf_LRU_free_block() may release mutex temporarily */
+		    && buf_block_get_state(block) == BUF_BLOCK_FILE_PAGE
+		    && buf_block_get_space(block) == space
+		    && buf_block_get_page_no(block) == page_no) {
 			/* Attempt to deallocate the uncompressed page
 			if the whole block cannot be deallocted. */
 
-			buf_LRU_free_block(&block->page, FALSE);
+			buf_LRU_free_block(&block->page, FALSE, TRUE);
 		}
 	}
 
-	buf_pool_mutex_exit();
+	//buf_pool_mutex_exit();
+	mutex_exit(&LRU_list_mutex);
 	mutex_exit(&block->mutex);
 }
 
--- a/storage/innodb_plugin/btr/btr0sea.c
+++ b/storage/innodb_plugin/btr/btr0sea.c
@@ -1925,7 +1925,8 @@
 	rec_offs_init(offsets_);
 
 	rw_lock_x_lock(&btr_search_latch);
-	buf_pool_mutex_enter();
+	//buf_pool_mutex_enter();
+	rw_lock_x_lock(&page_hash_latch);
 
 	cell_count = hash_get_n_cells(btr_search_sys->hash_index);
 
@@ -1933,11 +1934,13 @@
 		/* We release btr_search_latch every once in a while to
 		give other queries a chance to run. */
 		if ((i != 0) && ((i % chunk_size) == 0)) {
-			buf_pool_mutex_exit();
+			//buf_pool_mutex_exit();
+			rw_lock_x_unlock(&page_hash_latch);
 			rw_lock_x_unlock(&btr_search_latch);
 			os_thread_yield();
 			rw_lock_x_lock(&btr_search_latch);
-			buf_pool_mutex_enter();
+			//buf_pool_mutex_enter();
+			rw_lock_x_lock(&page_hash_latch);
 		}
 
 		node = hash_get_nth_cell(btr_search_sys->hash_index, i)->node;
@@ -2044,11 +2047,13 @@
 		/* We release btr_search_latch every once in a while to
 		give other queries a chance to run. */
 		if (i != 0) {
-			buf_pool_mutex_exit();
+			//buf_pool_mutex_exit();
+			rw_lock_x_unlock(&page_hash_latch);
 			rw_lock_x_unlock(&btr_search_latch);
 			os_thread_yield();
 			rw_lock_x_lock(&btr_search_latch);
-			buf_pool_mutex_enter();
+			//buf_pool_mutex_enter();
+			rw_lock_x_lock(&page_hash_latch);
 		}
 
 		if (!ha_validate(btr_search_sys->hash_index, i, end_index)) {
@@ -2056,7 +2061,8 @@
 		}
 	}
 
-	buf_pool_mutex_exit();
+	//buf_pool_mutex_exit();
+	rw_lock_x_unlock(&page_hash_latch);
 	rw_lock_x_unlock(&btr_search_latch);
 	if (UNIV_LIKELY_NULL(heap)) {
 		mem_heap_free(heap);
--- a/storage/innodb_plugin/buf/buf0buddy.c
+++ b/storage/innodb_plugin/buf/buf0buddy.c
@@ -47,7 +47,7 @@
 
 /** Validate a given zip_free list. */
 #define BUF_BUDDY_LIST_VALIDATE(i)				\
-	UT_LIST_VALIDATE(list, buf_page_t,			\
+	UT_LIST_VALIDATE(zip_list, buf_page_t,			\
 			 buf_pool->zip_free[i],			\
 			 ut_ad(buf_page_get_state(		\
 				       ut_list_node_313)	\
@@ -84,10 +84,11 @@
 	buf_page_t*	bpage,	/*!< in,own: block to be freed */
 	ulint		i)	/*!< in: index of buf_pool->zip_free[] */
 {
-	ut_ad(buf_pool_mutex_own());
+	//ut_ad(buf_pool_mutex_own());
+	ut_ad(mutex_own(&zip_free_mutex));
 	ut_ad(buf_page_get_state(bpage) == BUF_BLOCK_ZIP_FREE);
 	ut_ad(buf_pool->zip_free[i].start != bpage);
-	UT_LIST_ADD_FIRST(list, buf_pool->zip_free[i], bpage);
+	UT_LIST_ADD_FIRST(zip_list, buf_pool->zip_free[i], bpage);
 }
 
 /**********************************************************************//**
@@ -100,16 +101,17 @@
 	ulint		i)	/*!< in: index of buf_pool->zip_free[] */
 {
 #ifdef UNIV_DEBUG
-	buf_page_t*	prev = UT_LIST_GET_PREV(list, bpage);
-	buf_page_t*	next = UT_LIST_GET_NEXT(list, bpage);
+	buf_page_t*	prev = UT_LIST_GET_PREV(zip_list, bpage);
+	buf_page_t*	next = UT_LIST_GET_NEXT(zip_list, bpage);
 
 	ut_ad(!prev || buf_page_get_state(prev) == BUF_BLOCK_ZIP_FREE);
 	ut_ad(!next || buf_page_get_state(next) == BUF_BLOCK_ZIP_FREE);
 #endif /* UNIV_DEBUG */
 
-	ut_ad(buf_pool_mutex_own());
+	//ut_ad(buf_pool_mutex_own());
+	ut_ad(mutex_own(&zip_free_mutex));
 	ut_ad(buf_page_get_state(bpage) == BUF_BLOCK_ZIP_FREE);
-	UT_LIST_REMOVE(list, buf_pool->zip_free[i], bpage);
+	UT_LIST_REMOVE(zip_list, buf_pool->zip_free[i], bpage);
 }
 
 /**********************************************************************//**
@@ -123,7 +125,8 @@
 {
 	buf_page_t*	bpage;
 
-	ut_ad(buf_pool_mutex_own());
+	//ut_ad(buf_pool_mutex_own());
+	ut_ad(mutex_own(&zip_free_mutex));
 	ut_a(i < BUF_BUDDY_SIZES);
 	ut_a(i >= buf_buddy_get_slot(PAGE_ZIP_MIN_SIZE));
 
@@ -164,16 +167,19 @@
 void
 buf_buddy_block_free(
 /*=================*/
-	void*	buf)	/*!< in: buffer frame to deallocate */
+	void*	buf,	/*!< in: buffer frame to deallocate */
+	ibool	have_page_hash_mutex)
 {
 	const ulint	fold	= BUF_POOL_ZIP_FOLD_PTR(buf);
 	buf_page_t*	bpage;
 	buf_block_t*	block;
 
-	ut_ad(buf_pool_mutex_own());
+	//ut_ad(buf_pool_mutex_own());
 	ut_ad(!mutex_own(&buf_pool_zip_mutex));
 	ut_a(!ut_align_offset(buf, UNIV_PAGE_SIZE));
 
+	mutex_enter(&zip_hash_mutex);
+
 	HASH_SEARCH(hash, buf_pool->zip_hash, fold, buf_page_t*, bpage,
 		    ut_ad(buf_page_get_state(bpage) == BUF_BLOCK_MEMORY
 			  && bpage->in_zip_hash && !bpage->in_page_hash),
@@ -185,12 +191,14 @@
 	ut_d(bpage->in_zip_hash = FALSE);
 	HASH_DELETE(buf_page_t, hash, buf_pool->zip_hash, fold, bpage);
 
+	mutex_exit(&zip_hash_mutex);
+
 	ut_d(memset(buf, 0, UNIV_PAGE_SIZE));
 	UNIV_MEM_INVALID(buf, UNIV_PAGE_SIZE);
 
 	block = (buf_block_t*) bpage;
 	mutex_enter(&block->mutex);
-	buf_LRU_block_free_non_file_page(block);
+	buf_LRU_block_free_non_file_page(block, have_page_hash_mutex);
 	mutex_exit(&block->mutex);
 
 	ut_ad(buf_buddy_n_frames > 0);
@@ -206,7 +214,7 @@
 	buf_block_t*	block)	/*!< in: buffer frame to allocate */
 {
 	const ulint	fold = BUF_POOL_ZIP_FOLD(block);
-	ut_ad(buf_pool_mutex_own());
+	//ut_ad(buf_pool_mutex_own());
 	ut_ad(!mutex_own(&buf_pool_zip_mutex));
 	ut_ad(buf_block_get_state(block) == BUF_BLOCK_READY_FOR_USE);
 
@@ -218,7 +226,10 @@
 	ut_ad(!block->page.in_page_hash);
 	ut_ad(!block->page.in_zip_hash);
 	ut_d(block->page.in_zip_hash = TRUE);
+
+	mutex_enter(&zip_hash_mutex);
 	HASH_INSERT(buf_page_t, hash, buf_pool->zip_hash, fold, &block->page);
+	mutex_exit(&zip_hash_mutex);
 
 	ut_d(buf_buddy_n_frames++);
 }
@@ -269,25 +280,29 @@
 /*================*/
 	ulint	i,	/*!< in: index of buf_pool->zip_free[],
 			or BUF_BUDDY_SIZES */
-	ibool*	lru)	/*!< in: pointer to a variable that will be assigned
+	ibool*	lru,	/*!< in: pointer to a variable that will be assigned
 			TRUE if storage was allocated from the LRU list
 			and buf_pool_mutex was temporarily released */
+	ibool	have_page_hash_mutex)
 {
 	buf_block_t*	block;
 
 	ut_ad(lru);
-	ut_ad(buf_pool_mutex_own());
+	//ut_ad(buf_pool_mutex_own());
 	ut_ad(!mutex_own(&buf_pool_zip_mutex));
 	ut_ad(i >= buf_buddy_get_slot(PAGE_ZIP_MIN_SIZE));
 
 	if (i < BUF_BUDDY_SIZES) {
 		/* Try to allocate from the buddy system. */
+		mutex_enter(&zip_free_mutex);
 		block = buf_buddy_alloc_zip(i);
 
 		if (block) {
 
 			goto func_exit;
 		}
+
+		mutex_exit(&zip_free_mutex);
 	}
 
 	/* Try allocating from the buf_pool->free list. */
@@ -299,18 +314,29 @@
 	}
 
 	/* Try replacing an uncompressed page in the buffer pool. */
-	buf_pool_mutex_exit();
+	//buf_pool_mutex_exit();
+	mutex_exit(&LRU_list_mutex);
+	if (have_page_hash_mutex) {
+		rw_lock_x_unlock(&page_hash_latch);
+	}
 	block = buf_LRU_get_free_block();
 	*lru = TRUE;
-	buf_pool_mutex_enter();
+	//buf_pool_mutex_enter();
+	mutex_enter(&LRU_list_mutex);
+	if (have_page_hash_mutex) {
+		rw_lock_x_lock(&page_hash_latch);
+	}
 
 alloc_big:
 	buf_buddy_block_register(block);
 
+	mutex_enter(&zip_free_mutex);
 	block = buf_buddy_alloc_from(block->frame, i, BUF_BUDDY_SIZES);
 
 func_exit:
 	buf_buddy_stat[i].used++;
+	mutex_exit(&zip_free_mutex);
+
 	return(block);
 }
 
@@ -323,7 +349,8 @@
 /*===============*/
 	void*	src,	/*!< in: block to relocate */
 	void*	dst,	/*!< in: free block to relocate to */
-	ulint	i)	/*!< in: index of buf_pool->zip_free[] */
+	ulint	i,	/*!< in: index of buf_pool->zip_free[] */
+	ibool	have_page_hash_mutex)
 {
 	buf_page_t*	bpage;
 	const ulint	size	= BUF_BUDDY_LOW << i;
@@ -332,13 +359,20 @@
 	ulint		space;
 	ulint		page_no;
 
-	ut_ad(buf_pool_mutex_own());
+	//ut_ad(buf_pool_mutex_own());
+	ut_ad(mutex_own(&zip_free_mutex));
 	ut_ad(!mutex_own(&buf_pool_zip_mutex));
 	ut_ad(!ut_align_offset(src, size));
 	ut_ad(!ut_align_offset(dst, size));
 	ut_ad(i >= buf_buddy_get_slot(PAGE_ZIP_MIN_SIZE));
 	UNIV_MEM_ASSERT_W(dst, size);
 
+	if (!have_page_hash_mutex) {
+		mutex_exit(&zip_free_mutex);
+		mutex_enter(&LRU_list_mutex);
+		rw_lock_x_lock(&page_hash_latch);
+	}
+
 	/* We assume that all memory from buf_buddy_alloc()
 	is used for compressed page frames. */
 
@@ -372,6 +406,11 @@
 		added to buf_pool->page_hash yet.  Obviously,
 		it cannot be relocated. */
 
+		if (!have_page_hash_mutex) {
+			mutex_enter(&zip_free_mutex);
+			mutex_exit(&LRU_list_mutex);
+			rw_lock_x_unlock(&page_hash_latch);
+		}
 		return(FALSE);
 	}
 
@@ -381,18 +420,27 @@
 		For the sake of simplicity, give up. */
 		ut_ad(page_zip_get_size(&bpage->zip) < size);
 
+		if (!have_page_hash_mutex) {
+			mutex_enter(&zip_free_mutex);
+			mutex_exit(&LRU_list_mutex);
+			rw_lock_x_unlock(&page_hash_latch);
+		}
 		return(FALSE);
 	}
 
+	/* To keep latch order */
+	if (have_page_hash_mutex)
+		mutex_exit(&zip_free_mutex);
+
 	/* The block must have been allocated, but it may
 	contain uninitialized data. */
 	UNIV_MEM_ASSERT_W(src, size);
 
-	mutex = buf_page_get_mutex(bpage);
+	mutex = buf_page_get_mutex_enter(bpage);
 
-	mutex_enter(mutex);
+	mutex_enter(&zip_free_mutex);
 
-	if (buf_page_can_relocate(bpage)) {
+	if (mutex && buf_page_can_relocate(bpage)) {
 		/* Relocate the compressed page. */
 		ut_a(bpage->zip.data == src);
 		memcpy(dst, src, size);
@@ -406,10 +454,22 @@
 			buddy_stat->relocated_usec
 				+= ut_time_us(NULL) - usec;
 		}
+
+		if (!have_page_hash_mutex) {
+			mutex_exit(&LRU_list_mutex);
+			rw_lock_x_unlock(&page_hash_latch);
+		}
 		return(TRUE);
 	}
 
-	mutex_exit(mutex);
+	if (!have_page_hash_mutex) {
+		mutex_exit(&LRU_list_mutex);
+		rw_lock_x_unlock(&page_hash_latch);
+	}
+
+	if (mutex) {
+		mutex_exit(mutex);
+	}
 
 	return(FALSE);
 }
@@ -422,13 +482,15 @@
 /*===============*/
 	void*	buf,	/*!< in: block to be freed, must not be
 			pointed to by the buffer pool */
-	ulint	i)	/*!< in: index of buf_pool->zip_free[],
+	ulint	i,	/*!< in: index of buf_pool->zip_free[],
 			or BUF_BUDDY_SIZES */
+	ibool	have_page_hash_mutex)
 {
 	buf_page_t*	bpage;
 	buf_page_t*	buddy;
 
-	ut_ad(buf_pool_mutex_own());
+	//ut_ad(buf_pool_mutex_own());
+	ut_ad(mutex_own(&zip_free_mutex));
 	ut_ad(!mutex_own(&buf_pool_zip_mutex));
 	ut_ad(i <= BUF_BUDDY_SIZES);
 	ut_ad(i >= buf_buddy_get_slot(PAGE_ZIP_MIN_SIZE));
@@ -441,7 +503,9 @@
 	((buf_page_t*) buf)->state = BUF_BLOCK_ZIP_FREE;
 
 	if (i == BUF_BUDDY_SIZES) {
-		buf_buddy_block_free(buf);
+		mutex_exit(&zip_free_mutex);
+		buf_buddy_block_free(buf, have_page_hash_mutex);
+		mutex_enter(&zip_free_mutex);
 		return;
 	}
 
@@ -489,7 +553,7 @@
 
 		ut_a(bpage != buf);
 		UNIV_MEM_ASSERT_W(bpage, BUF_BUDDY_LOW << i);
-		bpage = UT_LIST_GET_NEXT(list, bpage);
+		bpage = UT_LIST_GET_NEXT(zip_list, bpage);
 	}
 
 #ifndef UNIV_DEBUG_VALGRIND
@@ -499,7 +563,7 @@
 	ut_d(BUF_BUDDY_LIST_VALIDATE(i));
 
 	/* The buddy is not free. Is there a free block of this size? */
-	bpage = UT_LIST_GET_FIRST(buf_pool->zip_free[i]);
+	bpage = UT_LIST_GET_LAST(buf_pool->zip_free[i]);
 
 	if (bpage) {
 
@@ -508,7 +572,7 @@
 		buf_buddy_remove_from_free(bpage, i);
 
 		/* Try to relocate the buddy of buf to the free block. */
-		if (buf_buddy_relocate(buddy, bpage, i)) {
+		if (buf_buddy_relocate(buddy, bpage, i, have_page_hash_mutex)) {
 
 			buddy->state = BUF_BLOCK_ZIP_FREE;
 			goto buddy_is_free;
--- a/storage/innodb_plugin/buf/buf0buf.c
+++ b/storage/innodb_plugin/buf/buf0buf.c
@@ -251,6 +251,12 @@
 /** mutex protecting the buffer pool struct and control blocks, except the
 read-write lock in them */
 UNIV_INTERN mutex_t		buf_pool_mutex;
+UNIV_INTERN mutex_t		LRU_list_mutex;
+UNIV_INTERN mutex_t		flush_list_mutex;
+UNIV_INTERN rw_lock_t		page_hash_latch;
+UNIV_INTERN mutex_t		free_list_mutex;
+UNIV_INTERN mutex_t		zip_free_mutex;
+UNIV_INTERN mutex_t		zip_hash_mutex;
 /** mutex protecting the control blocks of compressed-only pages
 (of type buf_page_t, not buf_block_t) */
 UNIV_INTERN mutex_t		buf_pool_zip_mutex;
@@ -661,9 +667,13 @@
 	block->page.in_zip_hash = FALSE;
 	block->page.in_flush_list = FALSE;
 	block->page.in_free_list = FALSE;
-	block->in_unzip_LRU_list = FALSE;
 #endif /* UNIV_DEBUG */
+	block->page.flush_list.prev = NULL;
+	block->page.flush_list.next = NULL;
+	block->page.zip_list.prev = NULL;
+	block->page.zip_list.next = NULL;
 	block->page.in_LRU_list = FALSE;
+	block->in_unzip_LRU_list = FALSE;
 #if defined UNIV_AHI_DEBUG || defined UNIV_DEBUG
 	block->n_pointers = 0;
 #endif /* UNIV_AHI_DEBUG || UNIV_DEBUG */
@@ -748,8 +758,10 @@
 		memset(block->frame, '\0', UNIV_PAGE_SIZE);
 #endif
 		/* Add the block to the free list */
-		UT_LIST_ADD_LAST(list, buf_pool->free, (&block->page));
+		mutex_enter(&free_list_mutex);
+		UT_LIST_ADD_LAST(free, buf_pool->free, (&block->page));
 		ut_d(block->page.in_free_list = TRUE);
+		mutex_exit(&free_list_mutex);
 
 		block++;
 		frame += UNIV_PAGE_SIZE;
@@ -774,7 +786,7 @@
 	ulint		i;
 
 	ut_ad(buf_pool);
-	ut_ad(buf_pool_mutex_own());
+	//ut_ad(buf_pool_mutex_own());
 
 	block = chunk->blocks;
 
@@ -826,7 +838,7 @@
 	ulint		i;
 
 	ut_ad(buf_pool);
-	ut_ad(buf_pool_mutex_own());
+	//ut_ad(buf_pool_mutex_own()); /*optimistic...*/
 
 	block = chunk->blocks;
 
@@ -881,8 +893,17 @@
 	/* 1. Initialize general fields
 	------------------------------- */
 	mutex_create(&buf_pool_mutex, SYNC_BUF_POOL);
+	mutex_create(&LRU_list_mutex, SYNC_BUF_LRU_LIST);
+	mutex_create(&flush_list_mutex, SYNC_BUF_FLUSH_LIST);
+	rw_lock_create(&page_hash_latch, SYNC_BUF_PAGE_HASH);
+	mutex_create(&free_list_mutex, SYNC_BUF_FREE_LIST);
+	mutex_create(&zip_free_mutex, SYNC_BUF_ZIP_FREE);
+	mutex_create(&zip_hash_mutex, SYNC_BUF_ZIP_HASH);
+
 	mutex_create(&buf_pool_zip_mutex, SYNC_BUF_BLOCK);
 
+	mutex_enter(&LRU_list_mutex);
+	rw_lock_x_lock(&page_hash_latch);
 	buf_pool_mutex_enter();
 
 	buf_pool->n_chunks = 1;
@@ -917,6 +938,8 @@
 	--------------------------- */
 	/* All fields are initialized by mem_zalloc(). */
 
+	mutex_exit(&LRU_list_mutex);
+	rw_lock_x_unlock(&page_hash_latch);
 	buf_pool_mutex_exit();
 
 	btr_search_sys_create(buf_pool->curr_size
@@ -1052,7 +1075,11 @@
 	buf_page_t*	b;
 	ulint		fold;
 
-	ut_ad(buf_pool_mutex_own());
+	//ut_ad(buf_pool_mutex_own());
+	ut_ad(mutex_own(&LRU_list_mutex));
+#ifdef UNIV_SYNC_DEBUG
+	ut_ad(rw_lock_own(&page_hash_latch, RW_LOCK_EX));
+#endif
 	ut_ad(mutex_own(buf_page_get_mutex(bpage)));
 	ut_a(buf_page_get_io_fix(bpage) == BUF_IO_NONE);
 	ut_a(bpage->buf_fix_count == 0);
@@ -1127,13 +1154,15 @@
 /*================*/
 	buf_page_t*	bpage)	/*!< in: buffer block of a file page */
 {
-	buf_pool_mutex_enter();
+	//buf_pool_mutex_enter();
+	mutex_enter(&LRU_list_mutex);
 
 	ut_a(buf_page_in_file(bpage));
 
 	buf_LRU_make_block_young(bpage);
 
-	buf_pool_mutex_exit();
+	//buf_pool_mutex_exit();
+	mutex_exit(&LRU_list_mutex);
 }
 
 /********************************************************************//**
@@ -1155,14 +1184,20 @@
 	ut_a(buf_page_in_file(bpage));
 
 	if (buf_page_peek_if_too_old(bpage)) {
-		buf_pool_mutex_enter();
+		//buf_pool_mutex_enter();
+		mutex_enter(&LRU_list_mutex);
 		buf_LRU_make_block_young(bpage);
-		buf_pool_mutex_exit();
+		//buf_pool_mutex_exit();
+		mutex_exit(&LRU_list_mutex);
 	} else if (!access_time) {
 		ulint	time_ms = ut_time_ms();
-		buf_pool_mutex_enter();
+		mutex_t*	block_mutex = buf_page_get_mutex_enter(bpage);
+		//buf_pool_mutex_enter();
+		if (block_mutex) {
 		buf_page_set_accessed(bpage, time_ms);
-		buf_pool_mutex_exit();
+		mutex_exit(block_mutex);
+		}
+		//buf_pool_mutex_exit();
 	}
 }
 
@@ -1178,7 +1213,8 @@
 {
 	buf_block_t*	block;
 
-	buf_pool_mutex_enter();
+	//buf_pool_mutex_enter();
+	rw_lock_s_lock(&page_hash_latch);
 
 	block = (buf_block_t*) buf_page_hash_get(space, offset);
 
@@ -1186,7 +1222,8 @@
 		block->check_index_page_at_flush = FALSE;
 	}
 
-	buf_pool_mutex_exit();
+	//buf_pool_mutex_exit();
+	rw_lock_s_unlock(&page_hash_latch);
 }
 
 /********************************************************************//**
@@ -1204,7 +1241,8 @@
 	buf_block_t*	block;
 	ibool		is_hashed;
 
-	buf_pool_mutex_enter();
+	//buf_pool_mutex_enter();
+	rw_lock_s_lock(&page_hash_latch);
 
 	block = (buf_block_t*) buf_page_hash_get(space, offset);
 
@@ -1214,7 +1252,8 @@
 		is_hashed = block->is_hashed;
 	}
 
-	buf_pool_mutex_exit();
+	//buf_pool_mutex_exit();
+	rw_lock_s_unlock(&page_hash_latch);
 
 	return(is_hashed);
 }
@@ -1235,7 +1274,8 @@
 {
 	buf_page_t*	bpage;
 
-	buf_pool_mutex_enter();
+	//buf_pool_mutex_enter();
+	rw_lock_s_lock(&page_hash_latch);
 
 	bpage = buf_page_hash_get(space, offset);
 
@@ -1245,7 +1285,8 @@
 		bpage->file_page_was_freed = TRUE;
 	}
 
-	buf_pool_mutex_exit();
+	//buf_pool_mutex_exit();
+	rw_lock_s_unlock(&page_hash_latch);
 
 	return(bpage);
 }
@@ -1265,7 +1306,8 @@
 {
 	buf_page_t*	bpage;
 
-	buf_pool_mutex_enter();
+	//buf_pool_mutex_enter();
+	rw_lock_s_lock(&page_hash_latch);
 
 	bpage = buf_page_hash_get(space, offset);
 
@@ -1273,7 +1315,8 @@
 		bpage->file_page_was_freed = FALSE;
 	}
 
-	buf_pool_mutex_exit();
+	//buf_pool_mutex_exit();
+	rw_lock_s_unlock(&page_hash_latch);
 
 	return(bpage);
 }
@@ -1307,8 +1350,9 @@
 	buf_pool->stat.n_page_gets++;
 
 	for (;;) {
-		buf_pool_mutex_enter();
+		//buf_pool_mutex_enter();
 lookup:
+		rw_lock_s_lock(&page_hash_latch);
 		bpage = buf_page_hash_get(space, offset);
 		if (bpage) {
 			break;
@@ -1316,7 +1360,8 @@
 
 		/* Page not in buf_pool: needs to be read from file */
 
-		buf_pool_mutex_exit();
+		//buf_pool_mutex_exit();
+		rw_lock_s_unlock(&page_hash_latch);
 
 		buf_read_page(space, zip_size, offset);
 
@@ -1328,34 +1373,58 @@
 	if (UNIV_UNLIKELY(!bpage->zip.data)) {
 		/* There is no compressed page. */
 err_exit:
-		buf_pool_mutex_exit();
+		//buf_pool_mutex_exit();
+		rw_lock_s_unlock(&page_hash_latch);
 		return(NULL);
 	}
 
+	block_mutex = buf_page_get_mutex_enter(bpage);
+
+	rw_lock_s_unlock(&page_hash_latch);
+
 	switch (buf_page_get_state(bpage)) {
 	case BUF_BLOCK_NOT_USED:
 	case BUF_BLOCK_READY_FOR_USE:
 	case BUF_BLOCK_MEMORY:
 	case BUF_BLOCK_REMOVE_HASH:
 	case BUF_BLOCK_ZIP_FREE:
+		if (block_mutex)
+			mutex_exit(block_mutex);
 		break;
 	case BUF_BLOCK_ZIP_PAGE:
 	case BUF_BLOCK_ZIP_DIRTY:
-		block_mutex = &buf_pool_zip_mutex;
-		mutex_enter(block_mutex);
+		ut_a(block_mutex == &buf_pool_zip_mutex);
 		bpage->buf_fix_count++;
 		goto got_block;
 	case BUF_BLOCK_FILE_PAGE:
-		block_mutex = &((buf_block_t*) bpage)->mutex;
+		ut_a(block_mutex == &((buf_block_t*) bpage)->mutex);
+
+		/* release mutex to obey to latch-order */
+		mutex_exit(block_mutex);
+
+		/* get LRU_list_mutex for buf_LRU_free_block() */
+		mutex_enter(&LRU_list_mutex);
 		mutex_enter(block_mutex);
 
-		/* Discard the uncompressed page frame if possible. */
-		if (buf_LRU_free_block(bpage, FALSE)) {
+		if (UNIV_UNLIKELY(bpage->space != space
+				  || bpage->offset != offset
+				  || !bpage->in_LRU_list
+				  || !bpage->zip.data)) {
+			/* someone should interrupt, retry */
+			mutex_exit(&LRU_list_mutex);
+			mutex_exit(block_mutex);
+			goto lookup;
+		}
 
+		/* Discard the uncompressed page frame if possible. */
+		if (buf_LRU_free_block(bpage, FALSE, TRUE)) {
+			mutex_exit(&LRU_list_mutex);
 			mutex_exit(block_mutex);
 			goto lookup;
 		}
 
+		mutex_exit(&LRU_list_mutex);
+
 		buf_block_buf_fix_inc((buf_block_t*) bpage,
 				      __FILE__, __LINE__);
 		goto got_block;
@@ -1368,7 +1437,7 @@
 	must_read = buf_page_get_io_fix(bpage) == BUF_IO_READ;
 	access_time = buf_page_is_accessed(bpage);
 
-	buf_pool_mutex_exit();
+	//buf_pool_mutex_exit();
 
 	mutex_exit(block_mutex);
 
@@ -1626,7 +1695,7 @@
 	const buf_block_t*	block)	/*!< in: pointer to block,
 					not dereferenced */
 {
-	ut_ad(buf_pool_mutex_own());
+	//ut_ad(buf_pool_mutex_own());
 
 	if (UNIV_UNLIKELY((((ulint) block) % sizeof *block) != 0)) {
 		/* The pointer should be aligned. */
@@ -1660,6 +1729,7 @@
 	ulint		fix_type;
 	ibool		must_read;
 	ulint		retries = 0;
+	mutex_t*	block_mutex = NULL;
 
 	ut_ad(mtr);
 	ut_ad(mtr->state == MTR_ACTIVE);
@@ -1687,17 +1757,23 @@
 	buf_pool->stat.n_page_gets++;
 loop:
 	block = guess;
-	buf_pool_mutex_enter();
+	//buf_pool_mutex_enter();
 
 	if (block) {
+		block_mutex = buf_page_get_mutex_enter((buf_page_t*)block);
+
 		/* If the guess is a compressed page descriptor that
 		has been allocated by buf_page_alloc_descriptor(),
 		it may have been freed by buf_relocate(). */
-		if (!buf_block_is_uncompressed(block)
+		if (!block_mutex) {
+			block = guess = NULL;
+		} else if (!buf_block_is_uncompressed(block)
 		    || offset != block->page.offset
 		    || space != block->page.space
 		    || buf_block_get_state(block) != BUF_BLOCK_FILE_PAGE) {
 
+			mutex_exit(block_mutex);
+
 			block = guess = NULL;
 		} else {
 			ut_ad(!block->page.in_zip_hash);
@@ -1706,14 +1782,20 @@
 	}
 
 	if (block == NULL) {
+		rw_lock_s_lock(&page_hash_latch);
 		block = (buf_block_t*) buf_page_hash_get(space, offset);
+		if (block) {
+			block_mutex = buf_page_get_mutex_enter((buf_page_t*)block);
+			ut_a(block_mutex);
+		}
+		rw_lock_s_unlock(&page_hash_latch);
 	}
 
 loop2:
 	if (block == NULL) {
 		/* Page not in buf_pool: needs to be read from file */
 
-		buf_pool_mutex_exit();
+		//buf_pool_mutex_exit();
 
 		if (mode == BUF_GET_IF_IN_POOL
 		    || mode == BUF_PEEK_IF_IN_POOL) {
@@ -1758,7 +1840,8 @@
 	if (must_read && (mode == BUF_GET_IF_IN_POOL
 			  || mode == BUF_PEEK_IF_IN_POOL)) {
 		/* The page is only being read to buffer */
-		buf_pool_mutex_exit();
+		//buf_pool_mutex_exit();
+		mutex_exit(block_mutex);
 
 		return(NULL);
 	}
@@ -1768,38 +1851,50 @@
 		ibool		success;
 
 	case BUF_BLOCK_FILE_PAGE:
+		if (block_mutex == &buf_pool_zip_mutex) {
+			/* it is wrong mutex... */
+			mutex_exit(block_mutex);
+			goto loop;
+		}
 		break;
 
 	case BUF_BLOCK_ZIP_PAGE:
 	case BUF_BLOCK_ZIP_DIRTY:
+		ut_ad(block_mutex == &buf_pool_zip_mutex);
 		bpage = &block->page;
 		/* Protect bpage->buf_fix_count. */
-		mutex_enter(&buf_pool_zip_mutex);
+		/* Already proteced here. */
+		//mutex_enter(&buf_pool_zip_mutex);
 
 		if (bpage->buf_fix_count
 		    || buf_page_get_io_fix(bpage) != BUF_IO_NONE) {
 			/* This condition often occurs when the buffer
 			is not buffer-fixed, but I/O-fixed by
 			buf_page_init_for_read(). */
-			mutex_exit(&buf_pool_zip_mutex);
+			//mutex_exit(&buf_pool_zip_mutex);
 wait_until_unfixed:
 			/* The block is buffer-fixed or I/O-fixed.
 			Try again later. */
-			buf_pool_mutex_exit();
+			//buf_pool_mutex_exit();
+			mutex_exit(block_mutex);
 			os_thread_sleep(WAIT_FOR_READ);
 
 			goto loop;
 		}
 
 		/* Allocate an uncompressed page. */
-		buf_pool_mutex_exit();
-		mutex_exit(&buf_pool_zip_mutex);
+		//buf_pool_mutex_exit();
+		//mutex_exit(&buf_pool_zip_mutex);
+		mutex_exit(block_mutex);
 
 		block = buf_LRU_get_free_block();
 		ut_a(block);
+		block_mutex = &block->mutex;
 
-		buf_pool_mutex_enter();
-		mutex_enter(&block->mutex);
+		//buf_pool_mutex_enter();
+		mutex_enter(&LRU_list_mutex);
+		rw_lock_x_lock(&page_hash_latch);
+		mutex_enter(block_mutex);
 
 		{
 			buf_page_t*	hash_bpage
@@ -1810,35 +1905,49 @@
 				while buf_pool_mutex was released.
 				Free the block that was allocated. */
 
-				buf_LRU_block_free_non_file_page(block);
-				mutex_exit(&block->mutex);
+				buf_LRU_block_free_non_file_page(block, TRUE);
+				mutex_exit(block_mutex);
 
 				block = (buf_block_t*) hash_bpage;
+				if (block) {
+					block_mutex = buf_page_get_mutex_enter((buf_page_t*)block);
+					ut_a(block_mutex);
+				}
+				rw_lock_x_unlock(&page_hash_latch);
+				mutex_exit(&LRU_list_mutex);
 				goto loop2;
 			}
 		}
 
+		mutex_enter(&buf_pool_zip_mutex);
+
 		if (UNIV_UNLIKELY
 		    (bpage->buf_fix_count
 		     || buf_page_get_io_fix(bpage) != BUF_IO_NONE)) {
 
+			mutex_exit(&buf_pool_zip_mutex);
 			/* The block was buffer-fixed or I/O-fixed
 			while buf_pool_mutex was not held by this thread.
 			Free the block that was allocated and try again.
 			This should be extremely unlikely. */
 
-			buf_LRU_block_free_non_file_page(block);
-			mutex_exit(&block->mutex);
+			buf_LRU_block_free_non_file_page(block, TRUE);
+			//mutex_exit(&block->mutex);
 
+			rw_lock_x_unlock(&page_hash_latch);
+			mutex_exit(&LRU_list_mutex);
 			goto wait_until_unfixed;
 		}
 
 		/* Move the compressed page from bpage to block,
 		and uncompress it. */
 
-		mutex_enter(&buf_pool_zip_mutex);
+		mutex_enter(&flush_list_mutex);
 
 		buf_relocate(bpage, &block->page);
+
+		rw_lock_x_unlock(&page_hash_latch);
+
 		buf_block_init_low(block);
 		block->lock_hash_val = lock_rec_hash(space, offset);
 
@@ -1848,7 +1957,7 @@
 		if (buf_page_get_state(&block->page)
 		    == BUF_BLOCK_ZIP_PAGE) {
 #if defined UNIV_DEBUG || defined UNIV_BUF_DEBUG
-			UT_LIST_REMOVE(list, buf_pool->zip_clean,
+			UT_LIST_REMOVE(zip_list, buf_pool->zip_clean,
 				       &block->page);
 #endif /* UNIV_DEBUG || UNIV_BUF_DEBUG */
 			ut_ad(!block->page.in_flush_list);
@@ -1858,6 +1967,8 @@
 							 &block->page);
 		}
 
+		mutex_exit(&flush_list_mutex);
+
 		/* Buffer-fix, I/O-fix, and X-latch the block
 		for the duration of the decompression.
 		Also add the block to the unzip_LRU list. */
@@ -1866,17 +1977,22 @@
 		/* Insert at the front of unzip_LRU list */
 		buf_unzip_LRU_add_block(block, FALSE);
 
+		mutex_exit(&LRU_list_mutex);
+
 		block->page.buf_fix_count = 1;
 		buf_block_set_io_fix(block, BUF_IO_READ);
 		rw_lock_x_lock_func(&block->lock, 0, file, line);
 
 		UNIV_MEM_INVALID(bpage, sizeof *bpage);
 
-		mutex_exit(&block->mutex);
+		mutex_exit(block_mutex);
 		mutex_exit(&buf_pool_zip_mutex);
+
+		mutex_enter(&buf_pool_mutex);
 		buf_pool->n_pend_unzip++;
+		mutex_exit(&buf_pool_mutex);
 
-		buf_pool_mutex_exit();
+		//buf_pool_mutex_exit();
 
 		buf_page_free_descriptor(bpage);
 
@@ -1891,12 +2007,15 @@
 		}
 
 		/* Unfix and unlatch the block. */
-		buf_pool_mutex_enter();
-		mutex_enter(&block->mutex);
+		//buf_pool_mutex_enter();
+		block_mutex = &block->mutex;
+		mutex_enter(block_mutex);
 		block->page.buf_fix_count--;
 		buf_block_set_io_fix(block, BUF_IO_NONE);
-		mutex_exit(&block->mutex);
+
+		mutex_enter(&buf_pool_mutex);
 		buf_pool->n_pend_unzip--;
+		mutex_exit(&buf_pool_mutex);
 		rw_lock_x_unlock(&block->lock);
 		break;
 
@@ -1911,7 +2030,7 @@
 
 	ut_ad(buf_block_get_state(block) == BUF_BLOCK_FILE_PAGE);
 
-	mutex_enter(&block->mutex);
+	//mutex_enter(&block->mutex);
 #if UNIV_WORD_SIZE == 4
 	/* On 32-bit systems, there is no padding in buf_page_t.  On
 	other systems, Valgrind could complain about uninitialized pad
@@ -1923,9 +2042,9 @@
 		/* Try to evict the block from the buffer pool, to use the
 		insert buffer as much as possible. */
 
-		if (buf_LRU_free_block(&block->page, TRUE)) {
-			buf_pool_mutex_exit();
-			mutex_exit(&block->mutex);
+		if (buf_LRU_free_block(&block->page, TRUE, FALSE)) {
+			//buf_pool_mutex_exit();
+			mutex_exit(block_mutex);
 			fprintf(stderr,
 				"innodb_change_buffering_debug evict %u %u\n",
 				(unsigned) space, (unsigned) offset);
@@ -1944,13 +2063,14 @@
 
 	buf_block_buf_fix_inc(block, file, line);
 
-	mutex_exit(&block->mutex);
+	//mutex_exit(&block->mutex);
 
 	/* Check if this is the first access to the page */
 
 	access_time = buf_page_is_accessed(&block->page);
 
-	buf_pool_mutex_exit();
+	//buf_pool_mutex_exit();
+	mutex_exit(block_mutex);
 
 	if (UNIV_LIKELY(mode != BUF_PEEK_IF_IN_POOL)) {
 		buf_page_set_accessed_make_young(&block->page, access_time);
@@ -2180,9 +2300,11 @@
 	mutex_exit(&block->mutex);
 
 	if (mode == BUF_MAKE_YOUNG && buf_page_peek_if_too_old(&block->page)) {
-		buf_pool_mutex_enter();
+		//buf_pool_mutex_enter();
+		mutex_enter(&LRU_list_mutex);
 		buf_LRU_make_block_young(&block->page);
-		buf_pool_mutex_exit();
+		//buf_pool_mutex_exit();
+		mutex_exit(&LRU_list_mutex);
 	} else if (!buf_page_is_accessed(&block->page)) {
 		/* Above, we do a dirty read on purpose, to avoid
 		mutex contention.  The field buf_page_t::access_time
@@ -2190,9 +2312,11 @@
 		field must be protected by mutex, however. */
 		ulint	time_ms = ut_time_ms();
 
-		buf_pool_mutex_enter();
+		//buf_pool_mutex_enter();
+		mutex_enter(&block->mutex);
 		buf_page_set_accessed(&block->page, time_ms);
-		buf_pool_mutex_exit();
+		//buf_pool_mutex_exit();
+		mutex_exit(&block->mutex);
 	}
 
 	ut_ad(!ibuf_inside() || (mode == BUF_KEEP_OLD));
@@ -2258,16 +2382,19 @@
 	ut_ad(mtr);
 	ut_ad(mtr->state == MTR_ACTIVE);
 
-	buf_pool_mutex_enter();
+	//buf_pool_mutex_enter();
+	rw_lock_s_lock(&page_hash_latch);
 	block = buf_block_hash_get(space_id, page_no);
 
 	if (!block) {
-		buf_pool_mutex_exit();
+		//buf_pool_mutex_exit();
+		rw_lock_s_unlock(&page_hash_latch);
 		return(NULL);
 	}
 
 	mutex_enter(&block->mutex);
-	buf_pool_mutex_exit();
+	//buf_pool_mutex_exit();
+	rw_lock_s_unlock(&page_hash_latch);
 
 #if defined UNIV_DEBUG || defined UNIV_BUF_DEBUG
 	ut_a(buf_block_get_state(block) == BUF_BLOCK_FILE_PAGE);
@@ -2354,7 +2481,10 @@
 {
 	buf_page_t*	hash_page;
 
-	ut_ad(buf_pool_mutex_own());
+	//ut_ad(buf_pool_mutex_own());
+#ifdef UNIV_SYNC_DEBUG
+	ut_ad(rw_lock_own(&page_hash_latch, RW_LOCK_EX));
+#endif
 	ut_ad(mutex_own(&(block->mutex)));
 	ut_a(buf_block_get_state(block) != BUF_BLOCK_FILE_PAGE);
 
@@ -2387,7 +2517,8 @@
 			(const void*) hash_page, (const void*) block);
 #if defined UNIV_DEBUG || defined UNIV_BUF_DEBUG
 		mutex_exit(&block->mutex);
-		buf_pool_mutex_exit();
+		//buf_pool_mutex_exit();
+		rw_lock_x_unlock(&page_hash_latch);
 		buf_print();
 		buf_LRU_print();
 		buf_validate();
@@ -2466,16 +2597,24 @@
 		ut_ad(block);
 	}
 
-	buf_pool_mutex_enter();
+	//buf_pool_mutex_enter();
+	mutex_enter(&LRU_list_mutex);
+	rw_lock_x_lock(&page_hash_latch);
 
 	if (buf_page_hash_get(space, offset)) {
 		/* The page is already in the buffer pool. */
 err_exit:
 		if (block) {
 			mutex_enter(&block->mutex);
-			buf_LRU_block_free_non_file_page(block);
+			mutex_exit(&LRU_list_mutex);
+			rw_lock_x_unlock(&page_hash_latch);
+			buf_LRU_block_free_non_file_page(block, FALSE);
 			mutex_exit(&block->mutex);
 		}
+		else {
+			mutex_exit(&LRU_list_mutex);
+			rw_lock_x_unlock(&page_hash_latch);
+		}
 
 		bpage = NULL;
 		goto func_exit;
@@ -2495,6 +2634,8 @@
 		mutex_enter(&block->mutex);
 		buf_page_init(space, offset, block);
 
+		rw_lock_x_unlock(&page_hash_latch);
+
 		/* The block must be put to the LRU list, to the old blocks */
 		buf_LRU_add_block(bpage, TRUE/* to old blocks */);
 
@@ -2522,7 +2663,7 @@
 			been added to buf_pool->LRU and
 			buf_pool->page_hash. */
 			mutex_exit(&block->mutex);
-			data = buf_buddy_alloc(zip_size, &lru);
+			data = buf_buddy_alloc(zip_size, &lru, FALSE);
 			mutex_enter(&block->mutex);
 			block->page.zip.data = data;
 
@@ -2535,6 +2676,7 @@
 			buf_unzip_LRU_add_block(block, TRUE);
 		}
 
+		mutex_exit(&LRU_list_mutex);
 		mutex_exit(&block->mutex);
 	} else {
 
@@ -2542,7 +2684,7 @@
 		control block (bpage), in order to avoid the
 		invocation of buf_buddy_relocate_block() on
 		uninitialized data. */
-		data = buf_buddy_alloc(zip_size, &lru);
+		data = buf_buddy_alloc(zip_size, &lru, TRUE);
 
 		/* If buf_buddy_alloc() allocated storage from the LRU list,
 		it released and reacquired buf_pool_mutex.  Thus, we must
@@ -2550,7 +2692,10 @@
 		if (UNIV_UNLIKELY(lru)
 		    && UNIV_LIKELY_NULL(buf_page_hash_get(space, offset))) {
 
-			buf_buddy_free(data, zip_size);
+			buf_buddy_free(data, zip_size, TRUE);
+
+			mutex_exit(&LRU_list_mutex);
+			rw_lock_x_unlock(&page_hash_latch);
 			bpage = NULL;
 			goto func_exit;
 		}
@@ -2581,20 +2726,28 @@
 		HASH_INSERT(buf_page_t, hash, buf_pool->page_hash,
 			    buf_page_address_fold(space, offset), bpage);
 
+		rw_lock_x_unlock(&page_hash_latch);
+
 		/* The block must be put to the LRU list, to the old blocks */
 		buf_LRU_add_block(bpage, TRUE/* to old blocks */);
 #if defined UNIV_DEBUG || defined UNIV_BUF_DEBUG
+		mutex_enter(&flush_list_mutex);
 		buf_LRU_insert_zip_clean(bpage);
+		mutex_exit(&flush_list_mutex);
 #endif /* UNIV_DEBUG || UNIV_BUF_DEBUG */
 
+		mutex_exit(&LRU_list_mutex);
+
 		buf_page_set_io_fix(bpage, BUF_IO_READ);
 
 		mutex_exit(&buf_pool_zip_mutex);
 	}
 
+	mutex_enter(&buf_pool_mutex);
 	buf_pool->n_pend_reads++;
+	mutex_exit(&buf_pool_mutex);
 func_exit:
-	buf_pool_mutex_exit();
+	//buf_pool_mutex_exit();
 
 	if (mode == BUF_READ_IBUF_PAGES_ONLY) {
 
@@ -2632,7 +2785,9 @@
 
 	free_block = buf_LRU_get_free_block();
 
-	buf_pool_mutex_enter();
+	//buf_pool_mutex_enter();
+	mutex_enter(&LRU_list_mutex);
+	rw_lock_x_lock(&page_hash_latch);
 
 	block = (buf_block_t*) buf_page_hash_get(space, offset);
 
@@ -2645,7 +2800,9 @@
 #endif /* UNIV_DEBUG_FILE_ACCESSES || UNIV_DEBUG */
 
 		/* Page can be found in buf_pool */
-		buf_pool_mutex_exit();
+		//buf_pool_mutex_exit();
+		mutex_exit(&LRU_list_mutex);
+		rw_lock_x_unlock(&page_hash_latch);
 
 		buf_block_free(free_block);
 
@@ -2667,6 +2824,7 @@
 	mutex_enter(&block->mutex);
 
 	buf_page_init(space, offset, block);
+	rw_lock_x_unlock(&page_hash_latch);
 
 	/* The block must be put to the LRU list */
 	buf_LRU_add_block(&block->page, FALSE);
@@ -2693,7 +2851,7 @@
 		the reacquisition of buf_pool_mutex.  We also must
 		defer this operation until after the block descriptor
 		has been added to buf_pool->LRU and buf_pool->page_hash. */
-		data = buf_buddy_alloc(zip_size, &lru);
+		data = buf_buddy_alloc(zip_size, &lru, FALSE);
 		mutex_enter(&block->mutex);
 		block->page.zip.data = data;
 
@@ -2711,7 +2869,8 @@
 
 	buf_page_set_accessed(&block->page, time_ms);
 
-	buf_pool_mutex_exit();
+	//buf_pool_mutex_exit();
+	mutex_exit(&LRU_list_mutex);
 
 	mtr_memo_push(mtr, block, MTR_MEMO_BUF_FIX);
 
@@ -2761,6 +2920,7 @@
 	enum buf_io_fix	io_type;
 	const ibool	uncompressed = (buf_page_get_state(bpage)
 					== BUF_BLOCK_FILE_PAGE);
+	mutex_t*	block_mutex;
 
 	ut_a(buf_page_in_file(bpage));
 
@@ -2894,8 +3054,13 @@
 		}
 	}
 
-	buf_pool_mutex_enter();
-	mutex_enter(buf_page_get_mutex(bpage));
+	//buf_pool_mutex_enter();
+	if (io_type == BUF_IO_WRITE) {
+		mutex_enter(&LRU_list_mutex);
+	}
+	block_mutex = buf_page_get_mutex_enter(bpage);
+	ut_a(block_mutex);
+	mutex_enter(&buf_pool_mutex);
 
 #ifdef UNIV_IBUF_COUNT_DEBUG
 	if (io_type == BUF_IO_WRITE || uncompressed) {
@@ -2935,6 +3100,11 @@
 
 		buf_flush_write_complete(bpage);
 
+		/* to keep consistency at buf_LRU_insert_zip_clean() */
+		//if (flush_type == BUF_FLUSH_LRU) { /* optimistic! */
+			mutex_exit(&LRU_list_mutex);
+		//}
+
 		if (uncompressed) {
 			rw_lock_s_unlock_gen(&((buf_block_t*) bpage)->lock,
 					     BUF_IO_WRITE);
@@ -2957,8 +3127,9 @@
 	}
 #endif /* UNIV_DEBUG */
 
-	mutex_exit(buf_page_get_mutex(bpage));
-	buf_pool_mutex_exit();
+	mutex_exit(&buf_pool_mutex);
+	mutex_exit(block_mutex);
+	//buf_pool_mutex_exit();
 }
 
 /*********************************************************************//**
@@ -3005,7 +3176,8 @@
 		freed = buf_LRU_search_and_free_block(100);
 	}
 
-	buf_pool_mutex_enter();
+	//buf_pool_mutex_enter();
+	mutex_enter(&LRU_list_mutex);
 
 	ut_ad(UT_LIST_GET_LEN(buf_pool->LRU) == 0);
 	ut_ad(UT_LIST_GET_LEN(buf_pool->unzip_LRU) == 0);
@@ -3018,7 +3190,8 @@
 	memset(&buf_pool->stat, 0x00, sizeof(buf_pool->stat));
 	buf_refresh_io_stats();
 
-	buf_pool_mutex_exit();
+	//buf_pool_mutex_exit();
+	mutex_exit(&LRU_list_mutex);
 }
 
 #if defined UNIV_DEBUG || defined UNIV_BUF_DEBUG
@@ -3043,7 +3216,10 @@
 
 	ut_ad(buf_pool);
 
-	buf_pool_mutex_enter();
+	//buf_pool_mutex_enter();
+	mutex_enter(&LRU_list_mutex);
+	rw_lock_x_lock(&page_hash_latch);
+	/* for keep the new latch order, it cannot validate correctly... */
 
 	chunk = buf_pool->chunks;
 
@@ -3142,7 +3318,7 @@
 	/* Check clean compressed-only blocks. */
 
 	for (b = UT_LIST_GET_FIRST(buf_pool->zip_clean); b;
-	     b = UT_LIST_GET_NEXT(list, b)) {
+	     b = UT_LIST_GET_NEXT(zip_list, b)) {
 		ut_a(buf_page_get_state(b) == BUF_BLOCK_ZIP_PAGE);
 		switch (buf_page_get_io_fix(b)) {
 		case BUF_IO_NONE:
@@ -3167,8 +3343,9 @@
 
 	/* Check dirty compressed-only blocks. */
 
+	mutex_enter(&flush_list_mutex);
 	for (b = UT_LIST_GET_FIRST(buf_pool->flush_list); b;
-	     b = UT_LIST_GET_NEXT(list, b)) {
+	     b = UT_LIST_GET_NEXT(flush_list, b)) {
 		ut_ad(b->in_flush_list);
 
 		switch (buf_page_get_state(b)) {
@@ -3213,6 +3390,7 @@
 		}
 		ut_a(buf_page_hash_get(b->space, b->offset) == b);
 	}
+	mutex_exit(&flush_list_mutex);
 
 	mutex_exit(&buf_pool_zip_mutex);
 
@@ -3224,19 +3402,27 @@
 	}
 
 	ut_a(UT_LIST_GET_LEN(buf_pool->LRU) == n_lru);
+	/* because of latching order with block->mutex, we cannot get free_list_mutex before that */
+/*
 	if (UT_LIST_GET_LEN(buf_pool->free) != n_free) {
 		fprintf(stderr, "Free list len %lu, free blocks %lu\n",
 			(ulong) UT_LIST_GET_LEN(buf_pool->free),
 			(ulong) n_free);
 		ut_error;
 	}
+*/
+	/* because of latching order with block->mutex, we cannot get flush_list_mutex before that */
+/*
 	ut_a(UT_LIST_GET_LEN(buf_pool->flush_list) == n_flush);
 
 	ut_a(buf_pool->n_flush[BUF_FLUSH_SINGLE_PAGE] == n_single_flush);
 	ut_a(buf_pool->n_flush[BUF_FLUSH_LIST] == n_list_flush);
 	ut_a(buf_pool->n_flush[BUF_FLUSH_LRU] == n_lru_flush);
+*/
 
-	buf_pool_mutex_exit();
+	//buf_pool_mutex_exit();
+	mutex_exit(&LRU_list_mutex);
+	rw_lock_x_unlock(&page_hash_latch);
 
 	ut_a(buf_LRU_validate());
 	ut_a(buf_flush_validate());
@@ -3270,7 +3456,10 @@
 	index_ids = mem_alloc(sizeof(dulint) * size);
 	counts = mem_alloc(sizeof(ulint) * size);
 
-	buf_pool_mutex_enter();
+	//buf_pool_mutex_enter();
+	mutex_enter(&LRU_list_mutex);
+	mutex_enter(&free_list_mutex);
+	mutex_enter(&flush_list_mutex);
 
 	fprintf(stderr,
 		"buf_pool size %lu\n"
@@ -3337,7 +3526,10 @@
 		}
 	}
 
-	buf_pool_mutex_exit();
+	//buf_pool_mutex_exit();
+	mutex_exit(&LRU_list_mutex);
+	mutex_exit(&free_list_mutex);
+	mutex_exit(&flush_list_mutex);
 
 	for (i = 0; i < n_found; i++) {
 		index = dict_index_get_if_in_cache(index_ids[i]);
@@ -3376,7 +3568,7 @@
 	ulint		i;
 	ulint		fixed_pages_number = 0;
 
-	buf_pool_mutex_enter();
+	//buf_pool_mutex_enter();
 
 	chunk = buf_pool->chunks;
 
@@ -3410,7 +3602,7 @@
 	/* Traverse the lists of clean and dirty compressed-only blocks. */
 
 	for (b = UT_LIST_GET_FIRST(buf_pool->zip_clean); b;
-	     b = UT_LIST_GET_NEXT(list, b)) {
+	     b = UT_LIST_GET_NEXT(zip_list, b)) {
 		ut_a(buf_page_get_state(b) == BUF_BLOCK_ZIP_PAGE);
 		ut_a(buf_page_get_io_fix(b) != BUF_IO_WRITE);
 
@@ -3420,8 +3612,9 @@
 		}
 	}
 
+	mutex_enter(&flush_list_mutex);
 	for (b = UT_LIST_GET_FIRST(buf_pool->flush_list); b;
-	     b = UT_LIST_GET_NEXT(list, b)) {
+	     b = UT_LIST_GET_NEXT(flush_list, b)) {
 		ut_ad(b->in_flush_list);
 
 		switch (buf_page_get_state(b)) {
@@ -3444,9 +3637,10 @@
 			break;
 		}
 	}
+	mutex_exit(&flush_list_mutex);
 
 	mutex_exit(&buf_pool_zip_mutex);
-	buf_pool_mutex_exit();
+	//buf_pool_mutex_exit();
 
 	return(fixed_pages_number);
 }
@@ -3504,7 +3698,11 @@
 
 	ut_ad(buf_pool);
 
-	buf_pool_mutex_enter();
+	//buf_pool_mutex_enter();
+	mutex_enter(&LRU_list_mutex);
+	mutex_enter(&free_list_mutex);
+	mutex_enter(&buf_pool_mutex);
+	mutex_enter(&flush_list_mutex);
 
 	fprintf(file,
 		"Buffer pool size        %lu\n"
@@ -3607,7 +3805,11 @@
 		buf_LRU_stat_sum.unzip, buf_LRU_stat_cur.unzip);
 
 	buf_refresh_io_stats();
-	buf_pool_mutex_exit();
+	//buf_pool_mutex_exit();
+	mutex_exit(&LRU_list_mutex);
+	mutex_exit(&free_list_mutex);
+	mutex_exit(&buf_pool_mutex);
+	mutex_exit(&flush_list_mutex);
 }
 
 /**********************************************************************//**
@@ -3634,7 +3836,7 @@
 
 	ut_ad(buf_pool);
 
-	buf_pool_mutex_enter();
+	//buf_pool_mutex_enter(); /* optimistic */
 
 	chunk = buf_pool->chunks;
 
@@ -3651,7 +3853,7 @@
 		}
 	}
 
-	buf_pool_mutex_exit();
+	//buf_pool_mutex_exit(); /* optimistic */
 
 	return(TRUE);
 }
@@ -3667,7 +3869,8 @@
 {
 	ibool	ret;
 
-	buf_pool_mutex_enter();
+	//buf_pool_mutex_enter();
+	mutex_enter(&buf_pool_mutex);
 
 	if (buf_pool->n_pend_reads + buf_pool->n_flush[BUF_FLUSH_LRU]
 	    + buf_pool->n_flush[BUF_FLUSH_LIST]
@@ -3677,7 +3880,8 @@
 		ret = TRUE;
 	}
 
-	buf_pool_mutex_exit();
+	//buf_pool_mutex_exit();
+	mutex_exit(&buf_pool_mutex);
 
 	return(ret);
 }
@@ -3692,11 +3896,13 @@
 {
 	ulint	len;
 
-	buf_pool_mutex_enter();
+	//buf_pool_mutex_enter();
+	mutex_enter(&free_list_mutex);
 
 	len = UT_LIST_GET_LEN(buf_pool->free);
 
-	buf_pool_mutex_exit();
+	//buf_pool_mutex_exit();
+	mutex_exit(&free_list_mutex);
 
 	return(len);
 }
--- a/storage/innodb_plugin/buf/buf0flu.c
+++ b/storage/innodb_plugin/buf/buf0flu.c
@@ -102,7 +102,8 @@
 	const ib_rbt_node_t*	c_node;
 	const ib_rbt_node_t*	p_node;
 
-	ut_ad(buf_pool_mutex_own());
+	//ut_ad(buf_pool_mutex_own());
+	ut_ad(mutex_own(&flush_list_mutex));
 
 	/* Insert this buffer into the rbt. */
 	c_node = rbt_insert(buf_pool->flush_rbt, &bpage, &bpage);
@@ -132,7 +133,8 @@
 	ibool	ret = FALSE;
 #endif /* UNIV_DEBUG */
 
-	ut_ad(buf_pool_mutex_own());
+	//ut_ad(buf_pool_mutex_own());
+	ut_ad(mutex_own(&flush_list_mutex));
 #ifdef UNIV_DEBUG
 	ret =
 #endif /* UNIV_DEBUG */
@@ -199,12 +201,14 @@
 buf_flush_init_flush_rbt(void)
 /*==========================*/
 {
-	buf_pool_mutex_enter();
+	//buf_pool_mutex_enter();
+	mutex_enter(&flush_list_mutex);
 
 	/* Create red black tree for speedy insertions in flush list. */
 	buf_pool->flush_rbt = rbt_create(sizeof(buf_page_t*),
 					 buf_flush_block_cmp);
-	buf_pool_mutex_exit();
+	//buf_pool_mutex_exit();
+	mutex_exit(&flush_list_mutex);
 }
 
 /********************************************************************//**
@@ -214,7 +218,8 @@
 buf_flush_free_flush_rbt(void)
 /*==========================*/
 {
-	buf_pool_mutex_enter();
+	//buf_pool_mutex_enter();
+	mutex_enter(&flush_list_mutex);
 
 #if defined UNIV_DEBUG || defined UNIV_BUF_DEBUG
 	ut_a(buf_flush_validate_low());
@@ -223,7 +228,8 @@
 	rbt_free(buf_pool->flush_rbt);
 	buf_pool->flush_rbt = NULL;
 
-	buf_pool_mutex_exit();
+	//buf_pool_mutex_exit();
+	mutex_exit(&flush_list_mutex);
 }
 
 /********************************************************************//**
@@ -234,7 +240,9 @@
 /*=============================*/
 	buf_block_t*	block)	/*!< in/out: block which is modified */
 {
-	ut_ad(buf_pool_mutex_own());
+	//ut_ad(buf_pool_mutex_own());
+	ut_ad(mutex_own(&block->mutex));
+	ut_ad(mutex_own(&flush_list_mutex));
 	ut_ad((UT_LIST_GET_FIRST(buf_pool->flush_list) == NULL)
 	      || (UT_LIST_GET_FIRST(buf_pool->flush_list)->oldest_modification
 		  <= block->page.oldest_modification));
@@ -252,7 +260,7 @@
 	ut_ad(!block->page.in_zip_hash);
 	ut_ad(!block->page.in_flush_list);
 	ut_d(block->page.in_flush_list = TRUE);
-	UT_LIST_ADD_FIRST(list, buf_pool->flush_list, &block->page);
+	UT_LIST_ADD_FIRST(flush_list, buf_pool->flush_list, &block->page);
 
 #ifdef UNIV_DEBUG_VALGRIND
 	{
@@ -283,7 +291,9 @@
 	buf_page_t*	prev_b;
 	buf_page_t*	b;
 
-	ut_ad(buf_pool_mutex_own());
+	//ut_ad(buf_pool_mutex_own());
+	ut_ad(mutex_own(&block->mutex));
+	ut_ad(mutex_own(&flush_list_mutex));
 	ut_ad(buf_block_get_state(block) == BUF_BLOCK_FILE_PAGE);
 
 	ut_ad(block->page.in_LRU_list);
@@ -324,14 +334,14 @@
 		       > block->page.oldest_modification) {
 			ut_ad(b->in_flush_list);
 			prev_b = b;
-			b = UT_LIST_GET_NEXT(list, b);
+			b = UT_LIST_GET_NEXT(flush_list, b);
 		}
 	}
 
 	if (prev_b == NULL) {
-		UT_LIST_ADD_FIRST(list, buf_pool->flush_list, &block->page);
+		UT_LIST_ADD_FIRST(flush_list, buf_pool->flush_list, &block->page);
 	} else {
-		UT_LIST_INSERT_AFTER(list, buf_pool->flush_list,
+		UT_LIST_INSERT_AFTER(flush_list, buf_pool->flush_list,
 				     prev_b, &block->page);
 	}
 
@@ -352,7 +362,7 @@
 				buf_page_in_file(bpage) and in the LRU list */
 {
 	//ut_ad(buf_pool_mutex_own());
-	//ut_ad(mutex_own(buf_page_get_mutex(bpage)));
+	ut_ad(mutex_own(buf_page_get_mutex(bpage)));
 	//ut_ad(bpage->in_LRU_list); /* optimistic use */
 
 	if (UNIV_LIKELY(bpage->in_LRU_list && buf_page_in_file(bpage))) {
@@ -387,12 +397,12 @@
 				buf_page_in_file(bpage) */
 	enum buf_flush	flush_type)/*!< in: BUF_FLUSH_LRU or BUF_FLUSH_LIST */
 {
-	ut_a(buf_page_in_file(bpage));
-	ut_ad(buf_pool_mutex_own());
+	//ut_a(buf_page_in_file(bpage));
+	//ut_ad(buf_pool_mutex_own()); /*optimistic...*/
 	ut_ad(mutex_own(buf_page_get_mutex(bpage)));
 	ut_ad(flush_type == BUF_FLUSH_LRU || BUF_FLUSH_LIST);
 
-	if (bpage->oldest_modification != 0
+	if (buf_page_in_file(bpage) && bpage->oldest_modification != 0
 	    && buf_page_get_io_fix(bpage) == BUF_IO_NONE) {
 		ut_ad(bpage->in_flush_list);
 
@@ -421,8 +431,11 @@
 /*=============*/
 	buf_page_t*	bpage)	/*!< in: pointer to the block in question */
 {
-	ut_ad(buf_pool_mutex_own());
+	//ut_ad(buf_pool_mutex_own());
 	ut_ad(mutex_own(buf_page_get_mutex(bpage)));
+
+	mutex_enter(&flush_list_mutex);
+
 	ut_ad(bpage->in_flush_list);
 
 	switch (buf_page_get_state(bpage)) {
@@ -433,17 +446,18 @@
 	case BUF_BLOCK_READY_FOR_USE:
 	case BUF_BLOCK_MEMORY:
 	case BUF_BLOCK_REMOVE_HASH:
+		mutex_exit(&flush_list_mutex);
 		ut_error;
 		return;
 	case BUF_BLOCK_ZIP_DIRTY:
 		buf_page_set_state(bpage, BUF_BLOCK_ZIP_PAGE);
-		UT_LIST_REMOVE(list, buf_pool->flush_list, bpage);
+		UT_LIST_REMOVE(flush_list, buf_pool->flush_list, bpage);
 #if defined UNIV_DEBUG || defined UNIV_BUF_DEBUG
 		buf_LRU_insert_zip_clean(bpage);
 #endif /* UNIV_DEBUG || UNIV_BUF_DEBUG */
 		break;
 	case BUF_BLOCK_FILE_PAGE:
-		UT_LIST_REMOVE(list, buf_pool->flush_list, bpage);
+		UT_LIST_REMOVE(flush_list, buf_pool->flush_list, bpage);
 		break;
 	}
 
@@ -458,8 +472,9 @@
 
 	bpage->oldest_modification = 0;
 
-	ut_d(UT_LIST_VALIDATE(list, buf_page_t, buf_pool->flush_list,
+	ut_d(UT_LIST_VALIDATE(flush_list, buf_page_t, buf_pool->flush_list,
 			      ut_ad(ut_list_node_313->in_flush_list)));
+	mutex_exit(&flush_list_mutex);
 }
 
 /********************************************************************//**
@@ -476,7 +491,8 @@
 	buf_page_t* prev;
 	buf_page_t* prev_b = NULL;
 
-	ut_ad(buf_pool_mutex_own());
+	//ut_ad(buf_pool_mutex_own());
+	ut_ad(mutex_own(&flush_list_mutex));
 
 	ut_ad(mutex_own(buf_page_get_mutex(bpage)));
 
@@ -494,18 +510,18 @@
 	because we assert on in_flush_list in comparison function. */
 	ut_d(bpage->in_flush_list = FALSE);
 
-	prev = UT_LIST_GET_PREV(list, bpage);
-	UT_LIST_REMOVE(list, buf_pool->flush_list, bpage);
+	prev = UT_LIST_GET_PREV(flush_list, bpage);
+	UT_LIST_REMOVE(flush_list, buf_pool->flush_list, bpage);
 
 	if (prev) {
 		ut_ad(prev->in_flush_list);
 		UT_LIST_INSERT_AFTER(
-			list,
+			flush_list,
 			buf_pool->flush_list,
 			prev, dpage);
 	} else {
 		UT_LIST_ADD_FIRST(
-			list,
+			flush_list,
 			buf_pool->flush_list,
 			dpage);
 	}
@@ -979,7 +995,9 @@
 	io_fixed and oldest_modification != 0.  Thus, it cannot be
 	relocated in the buffer pool or removed from flush_list or
 	LRU_list. */
-	ut_ad(!buf_pool_mutex_own());
+	//ut_ad(!buf_pool_mutex_own());
+	ut_ad(!mutex_own(&LRU_list_mutex));
+	ut_ad(!mutex_own(&flush_list_mutex));
 	ut_ad(!mutex_own(buf_page_get_mutex(bpage)));
 	ut_ad(buf_page_get_io_fix(bpage) == BUF_IO_WRITE);
 	ut_ad(bpage->oldest_modification != 0);
@@ -1057,7 +1075,7 @@
 /*===============*/
 	buf_block_t*	block)		/*!< in/out: buffer control block */
 {
-	ut_ad(buf_pool_mutex_own());
+	//ut_ad(buf_pool_mutex_own());
 	ut_ad(buf_block_get_state(block) == BUF_BLOCK_FILE_PAGE);
 	ut_ad(mutex_own(&block->mutex));
 
@@ -1065,8 +1083,11 @@
 		return(FALSE);
 	}
 
+	buf_pool_mutex_enter();
+
 	if (buf_pool->n_flush[BUF_FLUSH_LRU] > 0
 	    || buf_pool->init_flush[BUF_FLUSH_LRU]) {
+		buf_pool_mutex_exit();
 		/* There is already a flush batch of the same type running */
 		return(FALSE);
 	}
@@ -1139,12 +1160,19 @@
 	ibool		is_uncompressed;
 
 	ut_ad(flush_type == BUF_FLUSH_LRU || flush_type == BUF_FLUSH_LIST);
-	ut_ad(buf_pool_mutex_own());
+	//ut_ad(buf_pool_mutex_own());
+#ifdef UNIV_SYNC_DEBUG
+	ut_ad(rw_lock_own(&page_hash_latch, RW_LOCK_EX)
+	      || rw_lock_own(&page_hash_latch, RW_LOCK_SHARED));
+#endif
 	ut_ad(buf_page_in_file(bpage));
 
 	block_mutex = buf_page_get_mutex(bpage);
 	ut_ad(mutex_own(block_mutex));
 
+	mutex_enter(&buf_pool_mutex);
+	rw_lock_s_unlock(&page_hash_latch);
+
 	ut_ad(buf_flush_ready_for_flush(bpage, flush_type));
 
 	buf_page_set_io_fix(bpage, BUF_IO_WRITE);
@@ -1175,7 +1203,8 @@
 		}
 
 		mutex_exit(block_mutex);
-		buf_pool_mutex_exit();
+		//buf_pool_mutex_exit();
+		mutex_exit(&buf_pool_mutex);
 
 		/* Even though bpage is not protected by any mutex at
 		this point, it is safe to access bpage, because it is
@@ -1212,7 +1241,8 @@
 		immediately. */
 
 		mutex_exit(block_mutex);
-		buf_pool_mutex_exit();
+		//buf_pool_mutex_exit();
+		mutex_exit(&buf_pool_mutex);
 		break;
 
 	default:
@@ -1277,7 +1307,8 @@
 		high = fil_space_get_size(space);
 	}
 
-	buf_pool_mutex_enter();
+	//buf_pool_mutex_enter();
+	rw_lock_s_lock(&page_hash_latch);
 
 	for (i = low; i < high; i++) {
 
@@ -1296,11 +1327,9 @@
 		if (flush_type != BUF_FLUSH_LRU
 		    || i == offset
 		    || buf_page_is_old(bpage)) {
-			mutex_t* block_mutex = buf_page_get_mutex(bpage);
-
-			mutex_enter(block_mutex);
+			mutex_t* block_mutex = buf_page_get_mutex_enter(bpage);
 
-			if (buf_flush_ready_for_flush(bpage, flush_type)
+			if (block_mutex && buf_flush_ready_for_flush(bpage, flush_type)
 			    && (i == offset || !bpage->buf_fix_count)) {
 				/* We only try to flush those
 				neighbors != offset where the buf fix count is
@@ -1314,14 +1343,16 @@
 				ut_ad(!mutex_own(block_mutex));
 				count++;
 
-				buf_pool_mutex_enter();
-			} else {
+				//buf_pool_mutex_enter();
+				rw_lock_s_lock(&page_hash_latch);
+			} else if (block_mutex) {
 				mutex_exit(block_mutex);
 			}
 		}
 	}
 
-	buf_pool_mutex_exit();
+	//buf_pool_mutex_exit();
+	rw_lock_s_unlock(&page_hash_latch);
 
 	return(count);
 }
@@ -1352,9 +1383,11 @@
 					min_n), otherwise ignored */
 {
 	buf_page_t*	bpage;
+	buf_page_t*	prev_bpage	= NULL;
 	ulint		page_count	= 0;
 	ulint		space;
 	ulint		offset;
+	ulint		remaining	= 0;
 
 	ut_ad((flush_type == BUF_FLUSH_LRU)
 	      || (flush_type == BUF_FLUSH_LIST));
@@ -1362,20 +1395,28 @@
 	ut_ad((flush_type != BUF_FLUSH_LIST)
 	      || sync_thread_levels_empty_gen(TRUE));
 #endif /* UNIV_SYNC_DEBUG */
-	buf_pool_mutex_enter();
+	//buf_pool_mutex_enter();
+	mutex_enter(&buf_pool_mutex);
 
 	if ((buf_pool->n_flush[flush_type] > 0)
 	    || (buf_pool->init_flush[flush_type] == TRUE)) {
 
 		/* There is already a flush batch of the same type running */
 
-		buf_pool_mutex_exit();
+		//buf_pool_mutex_exit();
+		mutex_exit(&buf_pool_mutex);
 
 		return(ULINT_UNDEFINED);
 	}
 
 	buf_pool->init_flush[flush_type] = TRUE;
 
+	mutex_exit(&buf_pool_mutex);
+
+	if (flush_type == BUF_FLUSH_LRU) {
+		mutex_enter(&LRU_list_mutex);
+	}
+
 	for (;;) {
 flush_next:
 		/* If we have flushed enough, leave the loop */
@@ -1392,7 +1433,13 @@
 		} else {
 			ut_ad(flush_type == BUF_FLUSH_LIST);
 
+			mutex_enter(&flush_list_mutex);
+			remaining = UT_LIST_GET_LEN(buf_pool->flush_list);
 			bpage = UT_LIST_GET_LAST(buf_pool->flush_list);
+			if (bpage) {
+				prev_bpage = UT_LIST_GET_PREV(flush_list, bpage);
+			}
+			mutex_exit(&flush_list_mutex);
 			if (!bpage
 			    || bpage->oldest_modification >= lsn_limit) {
 				/* We have flushed enough */
@@ -1409,26 +1456,35 @@
 		function a pointer to a block in the list! */
 
 		do {
-			mutex_t*block_mutex = buf_page_get_mutex(bpage);
+			mutex_t*block_mutex = buf_page_get_mutex_enter(bpage);
 			ibool	ready;
 
-			ut_a(buf_page_in_file(bpage));
+			//ut_a(buf_page_in_file(bpage));
 
-			mutex_enter(block_mutex);
-			ready = buf_flush_ready_for_flush(bpage, flush_type);
-			mutex_exit(block_mutex);
+			if (block_mutex) {
+				ready = buf_flush_ready_for_flush(bpage, flush_type);
+				mutex_exit(block_mutex);
+			} else {
+				ready = FALSE;
+			}
 
 			if (ready) {
 				space = buf_page_get_space(bpage);
 				offset = buf_page_get_page_no(bpage);
 
-				buf_pool_mutex_exit();
+				//buf_pool_mutex_exit();
+				if (flush_type == BUF_FLUSH_LRU) {
+					mutex_exit(&LRU_list_mutex);
+				}
 
 				/* Try to flush also all the neighbors */
 				page_count += buf_flush_try_neighbors(
 					space, offset, flush_type, srv_flush_neighbor_pages);
 
-				buf_pool_mutex_enter();
+				//buf_pool_mutex_enter();
+				if (flush_type == BUF_FLUSH_LRU) {
+					mutex_enter(&LRU_list_mutex);
+				}
 				goto flush_next;
 
 			} else if (flush_type == BUF_FLUSH_LRU) {
@@ -1436,16 +1492,35 @@
 			} else {
 				ut_ad(flush_type == BUF_FLUSH_LIST);
 
-				bpage = UT_LIST_GET_PREV(list, bpage);
-				ut_ad(!bpage || bpage->in_flush_list);
+				mutex_enter(&flush_list_mutex);
+				bpage = UT_LIST_GET_PREV(flush_list, bpage);
+				//ut_ad(!bpage || bpage->in_flush_list); /* optimistic */
+				if (bpage != prev_bpage) {
+					/* the search may warp.. retrying */
+					bpage = NULL;
+				}
+				if (bpage) {
+					prev_bpage = UT_LIST_GET_PREV(flush_list, bpage);
+				}
+				mutex_exit(&flush_list_mutex);
+				remaining--;
 			}
 		} while (bpage != NULL);
 
+		if (remaining)
+			goto flush_next;
+
 		/* If we could not find anything to flush, leave the loop */
 
 		break;
 	}
 
+	if (flush_type == BUF_FLUSH_LRU) {
+		mutex_exit(&LRU_list_mutex);
+	}
+
+	mutex_enter(&buf_pool_mutex);
+
 	buf_pool->init_flush[flush_type] = FALSE;
 
 	if (buf_pool->n_flush[flush_type] == 0) {
@@ -1455,7 +1530,8 @@
 		os_event_set(buf_pool->no_flush[flush_type]);
 	}
 
-	buf_pool_mutex_exit();
+	//buf_pool_mutex_exit();
+	mutex_exit(&buf_pool_mutex);
 
 	buf_flush_buffered_writes();
 
@@ -1516,7 +1592,7 @@
 retry:
 	//buf_pool_mutex_enter();
 	if (have_LRU_mutex)
-		buf_pool_mutex_enter();
+		mutex_enter(&LRU_list_mutex);
 
 	n_replaceable = UT_LIST_GET_LEN(buf_pool->free);
 
@@ -1533,15 +1609,15 @@
 			bpage = UT_LIST_GET_LAST(buf_pool->LRU);
 			continue;
 		}
-		block_mutex = buf_page_get_mutex(bpage);
+		block_mutex = buf_page_get_mutex_enter(bpage);
 
-		mutex_enter(block_mutex);
-
-		if (buf_flush_ready_for_replace(bpage)) {
+		if (block_mutex && buf_flush_ready_for_replace(bpage)) {
 			n_replaceable++;
 		}
 
-		mutex_exit(block_mutex);
+		if (block_mutex) {
+			mutex_exit(block_mutex);
+		}
 
 		distance++;
 
@@ -1550,7 +1626,7 @@
 
 	//buf_pool_mutex_exit();
 	if (have_LRU_mutex)
-		buf_pool_mutex_exit();
+		mutex_exit(&LRU_list_mutex);
 
 	if (n_replaceable >= BUF_FLUSH_FREE_BLOCK_MARGIN) {
 
@@ -1717,7 +1793,7 @@
 	buf_page_t*		bpage;
 	const ib_rbt_node_t*	rnode = NULL;
 
-	UT_LIST_VALIDATE(list, buf_page_t, buf_pool->flush_list,
+	UT_LIST_VALIDATE(flush_list, buf_page_t, buf_pool->flush_list,
 			 ut_ad(ut_list_node_313->in_flush_list));
 
 	bpage = UT_LIST_GET_FIRST(buf_pool->flush_list);
@@ -1732,7 +1808,7 @@
 	while (bpage != NULL) {
 		const ib_uint64_t om = bpage->oldest_modification;
 		ut_ad(bpage->in_flush_list);
-		ut_a(buf_page_in_file(bpage));
+		//ut_a(buf_page_in_file(bpage)); /* optimistic */
 		ut_a(om > 0);
 
 		if (UNIV_LIKELY_NULL(buf_pool->flush_rbt)) {
@@ -1744,7 +1820,7 @@
 			rnode = rbt_next(buf_pool->flush_rbt, rnode);
 		}
 
-		bpage = UT_LIST_GET_NEXT(list, bpage);
+		bpage = UT_LIST_GET_NEXT(flush_list, bpage);
 
 		ut_a(!bpage || om >= bpage->oldest_modification);
 	}
@@ -1766,11 +1842,13 @@
 {
 	ibool	ret;
 
-	buf_pool_mutex_enter();
+	//buf_pool_mutex_enter();
+	mutex_enter(&flush_list_mutex);
 
 	ret = buf_flush_validate_low();
 
-	buf_pool_mutex_exit();
+	//buf_pool_mutex_exit();
+	mutex_exit(&flush_list_mutex);
 
 	return(ret);
 }
--- a/storage/innodb_plugin/buf/buf0lru.c
+++ b/storage/innodb_plugin/buf/buf0lru.c
@@ -145,8 +145,9 @@
 void
 buf_LRU_block_free_hashed_page(
 /*===========================*/
-	buf_block_t*	block);	/*!< in: block, must contain a file page and
+	buf_block_t*	block,	/*!< in: block, must contain a file page and
 				be in a state where it can be freed */
+	ibool		have_page_hash_mutex);
 
 /******************************************************************//**
 Determines if the unzip_LRU list should be used for evicting a victim
@@ -154,16 +155,21 @@
 @return	TRUE if should use unzip_LRU */
 UNIV_INLINE
 ibool
-buf_LRU_evict_from_unzip_LRU(void)
+buf_LRU_evict_from_unzip_LRU(
+	ibool		have_LRU_mutex)
 /*==============================*/
 {
 	ulint	io_avg;
 	ulint	unzip_avg;
 
-	ut_ad(buf_pool_mutex_own());
+	//ut_ad(buf_pool_mutex_own());
 
+	if (!have_LRU_mutex)
+		mutex_enter(&LRU_list_mutex);
 	/* If the unzip_LRU list is empty, we can only use the LRU. */
 	if (UT_LIST_GET_LEN(buf_pool->unzip_LRU) == 0) {
+		if (!have_LRU_mutex)
+			mutex_exit(&LRU_list_mutex);
 		return(FALSE);
 	}
 
@@ -172,14 +178,20 @@
 	decompressed pages in the buffer pool. */
 	if (UT_LIST_GET_LEN(buf_pool->unzip_LRU)
 	    <= UT_LIST_GET_LEN(buf_pool->LRU) / 10) {
+		if (!have_LRU_mutex)
+			mutex_exit(&LRU_list_mutex);
 		return(FALSE);
 	}
 
 	/* If eviction hasn't started yet, we assume by default
 	that a workload is disk bound. */
 	if (buf_pool->freed_page_clock == 0) {
+		if (!have_LRU_mutex)
+			mutex_exit(&LRU_list_mutex);
 		return(TRUE);
 	}
+	if (!have_LRU_mutex)
+		mutex_exit(&LRU_list_mutex);
 
 	/* Calculate the average over past intervals, and add the values
 	of the current interval. */
@@ -245,18 +257,25 @@
 
 	page_arr = ut_malloc(sizeof(ulint)
 			     * BUF_LRU_DROP_SEARCH_HASH_SIZE);
-	buf_pool_mutex_enter();
+	//buf_pool_mutex_enter();
+	mutex_enter(&LRU_list_mutex);
 	num_entries = 0;
 
 scan_again:
 	bpage = UT_LIST_GET_LAST(buf_pool->LRU);
 
 	while (bpage != NULL) {
+		/* bpage->state,space,io_fix,buf_fix_count are protected by block_mutex at XtraDB */
+		mutex_t*	block_mutex = buf_page_get_mutex_enter(bpage);
 		buf_page_t*	prev_bpage;
 		ibool		is_fixed;
 
 		prev_bpage = UT_LIST_GET_PREV(LRU, bpage);
 
+		if (UNIV_UNLIKELY(!block_mutex)) {
+			goto next_page;
+		}
+
 		ut_a(buf_page_in_file(bpage));
 
 		if (buf_page_get_state(bpage) != BUF_BLOCK_FILE_PAGE
@@ -265,23 +284,27 @@
 			/* Compressed pages are never hashed.
 			Skip blocks of other tablespaces.
 			Skip I/O-fixed blocks (to be dealt with later). */
+			mutex_exit(block_mutex);
 next_page:
 			bpage = prev_bpage;
 			continue;
 		}
 
-		mutex_enter(&((buf_block_t*) bpage)->mutex);
+		//mutex_enter(&((buf_block_t*) bpage)->mutex);
 		is_fixed = bpage->buf_fix_count > 0
 			|| !((buf_block_t*) bpage)->is_hashed;
-		mutex_exit(&((buf_block_t*) bpage)->mutex);
+		//mutex_exit(&((buf_block_t*) bpage)->mutex);
 
 		if (is_fixed) {
+			mutex_exit(block_mutex);
 			goto next_page;
 		}
 
 		/* Store the page number so that we can drop the hash
 		index in a batch later. */
 		page_arr[num_entries] = bpage->offset;
+		mutex_exit(block_mutex);
+
 		ut_a(num_entries < BUF_LRU_DROP_SEARCH_HASH_SIZE);
 		++num_entries;
 
@@ -291,10 +314,12 @@
 
 		/* Array full. We release the buf_pool_mutex to
 		obey the latching order. */
-		buf_pool_mutex_exit();
+		//buf_pool_mutex_exit();
+		mutex_exit(&LRU_list_mutex);
 		buf_LRU_drop_page_hash_batch(id, zip_size, page_arr,
 					     num_entries);
-		buf_pool_mutex_enter();
+		//buf_pool_mutex_enter();
+		mutex_enter(&LRU_list_mutex);
 		num_entries = 0;
 
 		/* Note that we released the buf_pool mutex above
@@ -313,13 +338,23 @@
 		/* If, however, bpage has been removed from LRU list
 		to the free list then we should restart the scan.
 		bpage->state is protected by buf_pool mutex. */
+
+		/* obtain block_mutex again to avoid race condition of bpage->state */
+		block_mutex = buf_page_get_mutex_enter(bpage);
+		if (!block_mutex) {
+			goto scan_again;
+		}
+
 		if (bpage
 		    && buf_page_get_state(bpage) != BUF_BLOCK_FILE_PAGE) {
+			mutex_exit(block_mutex);
 			goto scan_again;
 		}
+		mutex_exit(block_mutex);
 	}
 
-	buf_pool_mutex_exit();
+	//buf_pool_mutex_exit();
+	mutex_exit(&LRU_list_mutex);
 
 	/* Drop any remaining batch of search hashed pages. */
 	buf_LRU_drop_page_hash_batch(id, zip_size, page_arr, num_entries);
@@ -347,7 +382,9 @@
 	buf_LRU_drop_page_hash_for_tablespace(id);
 
 scan_again:
-	buf_pool_mutex_enter();
+	//buf_pool_mutex_enter();
+	mutex_enter(&LRU_list_mutex);
+	rw_lock_x_lock(&page_hash_latch);
 
 	all_freed = TRUE;
 
@@ -377,8 +414,15 @@
 			all_freed = FALSE;
 			goto next_page;
 		} else {
-			block_mutex = buf_page_get_mutex(bpage);
-			mutex_enter(block_mutex);
+			block_mutex = buf_page_get_mutex_enter(bpage);
+
+			if (!block_mutex) {
+				/* It may be impossible case...
+				Something wrong, so will be scan_again */
+
+				all_freed = FALSE;
+				goto next_page;
+			}
 
 			if (bpage->buf_fix_count > 0) {
 
@@ -411,7 +455,9 @@
 			ulint	page_no;
 			ulint	zip_size;
 
-			buf_pool_mutex_exit();
+			//buf_pool_mutex_exit();
+			mutex_exit(&LRU_list_mutex);
+			rw_lock_x_unlock(&page_hash_latch);
 
 			zip_size = buf_page_get_zip_size(bpage);
 			page_no = buf_page_get_page_no(bpage);
@@ -435,7 +481,7 @@
 
 		if (buf_LRU_block_remove_hashed_page(bpage, TRUE)
 		    != BUF_BLOCK_ZIP_FREE) {
-			buf_LRU_block_free_hashed_page((buf_block_t*) bpage);
+			buf_LRU_block_free_hashed_page((buf_block_t*) bpage, TRUE);
 			mutex_exit(block_mutex);
 		} else {
 			/* The block_mutex should have been released
@@ -448,7 +494,9 @@
 		bpage = prev_bpage;
 	}
 
-	buf_pool_mutex_exit();
+	//buf_pool_mutex_exit();
+	mutex_exit(&LRU_list_mutex);
+	rw_lock_x_unlock(&page_hash_latch);
 
 	if (!all_freed) {
 		os_thread_sleep(20000);
@@ -468,7 +516,9 @@
 {
 	buf_page_t*	b;
 
-	ut_ad(buf_pool_mutex_own());
+	//ut_ad(buf_pool_mutex_own());
+	ut_ad(mutex_own(&LRU_list_mutex));
+	ut_ad(mutex_own(&flush_list_mutex));
 	ut_ad(buf_page_get_state(bpage) == BUF_BLOCK_ZIP_PAGE);
 
 	/* Find the first successor of bpage in the LRU list
@@ -476,17 +526,17 @@
 	b = bpage;
 	do {
 		b = UT_LIST_GET_NEXT(LRU, b);
-	} while (b && buf_page_get_state(b) != BUF_BLOCK_ZIP_PAGE);
+	} while (b && (buf_page_get_state(b) != BUF_BLOCK_ZIP_PAGE || !b->in_LRU_list));
 
 	/* Insert bpage before b, i.e., after the predecessor of b. */
 	if (b) {
-		b = UT_LIST_GET_PREV(list, b);
+		b = UT_LIST_GET_PREV(zip_list, b);
 	}
 
 	if (b) {
-		UT_LIST_INSERT_AFTER(list, buf_pool->zip_clean, b, bpage);
+		UT_LIST_INSERT_AFTER(zip_list, buf_pool->zip_clean, b, bpage);
 	} else {
-		UT_LIST_ADD_FIRST(list, buf_pool->zip_clean, bpage);
+		UT_LIST_ADD_FIRST(zip_list, buf_pool->zip_clean, bpage);
 	}
 }
 #endif /* UNIV_DEBUG || UNIV_BUF_DEBUG */
@@ -499,16 +549,17 @@
 ibool
 buf_LRU_free_from_unzip_LRU_list(
 /*=============================*/
-	ulint	n_iterations)	/*!< in: how many times this has been called
+	ulint	n_iterations,	/*!< in: how many times this has been called
 				repeatedly without result: a high value means
 				that we should search farther; we will search
 				n_iterations / 5 of the unzip_LRU list,
 				or nothing if n_iterations >= 5 */
+	ibool	have_LRU_mutex)
 {
 	buf_block_t*	block;
 	ulint		distance;
 
-	ut_ad(buf_pool_mutex_own());
+	//ut_ad(buf_pool_mutex_own()); /* optimistic */
 
 	/* Theoratically it should be much easier to find a victim
 	from unzip_LRU as we can choose even a dirty block (as we'll
@@ -518,7 +569,7 @@
 	if we have done five iterations so far. */
 
 	if (UNIV_UNLIKELY(n_iterations >= 5)
-	    || !buf_LRU_evict_from_unzip_LRU()) {
+	    || !buf_LRU_evict_from_unzip_LRU(have_LRU_mutex)) {
 
 		return(FALSE);
 	}
@@ -526,18 +577,25 @@
 	distance = 100 + (n_iterations
 			  * UT_LIST_GET_LEN(buf_pool->unzip_LRU)) / 5;
 
+restart:
 	for (block = UT_LIST_GET_LAST(buf_pool->unzip_LRU);
 	     UNIV_LIKELY(block != NULL) && UNIV_LIKELY(distance > 0);
 	     block = UT_LIST_GET_PREV(unzip_LRU, block), distance--) {
 
 		ibool freed;
 
+		mutex_enter(&block->mutex);
+		if (!block->in_unzip_LRU_list || !block->page.in_LRU_list
+		    || buf_block_get_state(block) != BUF_BLOCK_FILE_PAGE) {
+			mutex_exit(&block->mutex);
+			goto restart;
+		}
+
 		ut_ad(buf_block_get_state(block) == BUF_BLOCK_FILE_PAGE);
 		ut_ad(block->in_unzip_LRU_list);
 		ut_ad(block->page.in_LRU_list);
 
-		mutex_enter(&block->mutex);
-		freed = buf_LRU_free_block(&block->page, FALSE);
+		freed = buf_LRU_free_block(&block->page, FALSE, have_LRU_mutex);
 		mutex_exit(&block->mutex);
 
 		if (freed) {
@@ -555,34 +613,45 @@
 ibool
 buf_LRU_free_from_common_LRU_list(
 /*==============================*/
-	ulint	n_iterations)	/*!< in: how many times this has been called
+	ulint	n_iterations,	/*!< in: how many times this has been called
 				repeatedly without result: a high value means
 				that we should search farther; if
 				n_iterations < 10, then we search
 				n_iterations / 10 * buf_pool->curr_size
 				pages from the end of the LRU list */
+	ibool	have_LRU_mutex)
 {
 	buf_page_t*	bpage;
 	ulint		distance;
 
-	ut_ad(buf_pool_mutex_own());
+	//ut_ad(buf_pool_mutex_own()); /* optimistic */
 
 	distance = 100 + (n_iterations * buf_pool->curr_size) / 10;
 
+restart:
 	for (bpage = UT_LIST_GET_LAST(buf_pool->LRU);
 	     UNIV_LIKELY(bpage != NULL) && UNIV_LIKELY(distance > 0);
 	     bpage = UT_LIST_GET_PREV(LRU, bpage), distance--) {
 
 		ibool		freed;
 		unsigned	accessed;
-		mutex_t*	block_mutex = buf_page_get_mutex(bpage);
+		mutex_t*	block_mutex = buf_page_get_mutex_enter(bpage);
+
+		if (!block_mutex) {
+			goto restart;
+		}
+
+		if (!bpage->in_LRU_list
+		    || !buf_page_in_file(bpage)) {
+			mutex_exit(block_mutex);
+			goto restart;
+		}
 
 		ut_ad(buf_page_in_file(bpage));
 		ut_ad(bpage->in_LRU_list);
 
-		mutex_enter(block_mutex);
 		accessed = buf_page_is_accessed(bpage);
-		freed = buf_LRU_free_block(bpage, TRUE);
+		freed = buf_LRU_free_block(bpage, TRUE, have_LRU_mutex);
 		mutex_exit(block_mutex);
 
 		if (freed) {
@@ -616,22 +685,33 @@
 				n_iterations / 5 of the unzip_LRU list. */
 {
 	ibool	freed = FALSE;
+	ibool	have_LRU_mutex = FALSE;
 
-	buf_pool_mutex_enter();
+	if (UT_LIST_GET_LEN(buf_pool->unzip_LRU))
+		have_LRU_mutex = TRUE;
 
-	freed = buf_LRU_free_from_unzip_LRU_list(n_iterations);
+	/* optimistic search... */
+	//buf_pool_mutex_enter();
+	if (have_LRU_mutex)
+		mutex_enter(&LRU_list_mutex);
+
+	freed = buf_LRU_free_from_unzip_LRU_list(n_iterations, have_LRU_mutex);
 
 	if (!freed) {
-		freed = buf_LRU_free_from_common_LRU_list(n_iterations);
+		freed = buf_LRU_free_from_common_LRU_list(n_iterations, have_LRU_mutex);
 	}
 
+	mutex_enter(&buf_pool_mutex);
 	if (!freed) {
 		buf_pool->LRU_flush_ended = 0;
 	} else if (buf_pool->LRU_flush_ended > 0) {
 		buf_pool->LRU_flush_ended--;
 	}
+	mutex_exit(&buf_pool_mutex);
 
-	buf_pool_mutex_exit();
+	//buf_pool_mutex_exit();
+	if (have_LRU_mutex)
+		mutex_exit(&LRU_list_mutex);
 
 	return(freed);
 }
@@ -649,18 +729,22 @@
 buf_LRU_try_free_flushed_blocks(void)
 /*=================================*/
 {
-	buf_pool_mutex_enter();
+	//buf_pool_mutex_enter();
+	mutex_enter(&buf_pool_mutex);
 
 	while (buf_pool->LRU_flush_ended > 0) {
 
-		buf_pool_mutex_exit();
+		//buf_pool_mutex_exit();
+		mutex_exit(&buf_pool_mutex);
 
 		buf_LRU_search_and_free_block(1);
 
-		buf_pool_mutex_enter();
+		//buf_pool_mutex_enter();
+		mutex_enter(&buf_pool_mutex);
 	}
 
-	buf_pool_mutex_exit();
+	//buf_pool_mutex_exit();
+	mutex_exit(&buf_pool_mutex);
 }
 
 /******************************************************************//**
@@ -675,7 +759,9 @@
 {
 	ibool	ret	= FALSE;
 
-	buf_pool_mutex_enter();
+	//buf_pool_mutex_enter();
+	mutex_enter(&LRU_list_mutex);
+	mutex_enter(&free_list_mutex);
 
 	if (!recv_recovery_on && UT_LIST_GET_LEN(buf_pool->free)
 	    + UT_LIST_GET_LEN(buf_pool->LRU) < buf_pool->curr_size / 4) {
@@ -683,7 +769,9 @@
 		ret = TRUE;
 	}
 
-	buf_pool_mutex_exit();
+	//buf_pool_mutex_exit();
+	mutex_exit(&LRU_list_mutex);
+	mutex_exit(&free_list_mutex);
 
 	return(ret);
 }
@@ -699,9 +787,10 @@
 {
 	buf_block_t*	block;
 
-	ut_ad(buf_pool_mutex_own());
+	//ut_ad(buf_pool_mutex_own());
 
-	block = (buf_block_t*) UT_LIST_GET_FIRST(buf_pool->free);
+	mutex_enter(&free_list_mutex);
+	block = (buf_block_t*) UT_LIST_GET_LAST(buf_pool->free);
 
 	if (block) {
 		ut_ad(block->page.in_free_list);
@@ -709,7 +798,9 @@
 		ut_ad(!block->page.in_flush_list);
 		ut_ad(!block->page.in_LRU_list);
 		ut_a(!buf_page_in_file(&block->page));
-		UT_LIST_REMOVE(list, buf_pool->free, (&block->page));
+		UT_LIST_REMOVE(free, buf_pool->free, (&block->page));
+
+		mutex_exit(&free_list_mutex);
 
 		mutex_enter(&block->mutex);
 
@@ -717,6 +808,8 @@
 		UNIV_MEM_ALLOC(block->frame, UNIV_PAGE_SIZE);
 
 		mutex_exit(&block->mutex);
+	} else {
+		mutex_exit(&free_list_mutex);
 	}
 
 	return(block);
@@ -738,7 +831,7 @@
 	ibool		mon_value_was	= FALSE;
 	ibool		started_monitor	= FALSE;
 loop:
-	buf_pool_mutex_enter();
+	//buf_pool_mutex_enter();
 
 	if (!recv_recovery_on && UT_LIST_GET_LEN(buf_pool->free)
 	    + UT_LIST_GET_LEN(buf_pool->LRU) < buf_pool->curr_size / 20) {
@@ -806,7 +899,7 @@
 
 	/* If there is a block in the free list, take it */
 	block = buf_LRU_get_free_only();
-	buf_pool_mutex_exit();
+	//buf_pool_mutex_exit();
 
 	if (block) {
 		memset(&block->page.zip, 0, sizeof block->page.zip);
@@ -868,18 +961,21 @@
 
 	os_aio_simulated_wake_handler_threads();
 
-	buf_pool_mutex_enter();
+	//buf_pool_mutex_enter();
+	mutex_enter(&buf_pool_mutex);
 
 	if (buf_pool->LRU_flush_ended > 0) {
 		/* We have written pages in an LRU flush. To make the insert
 		buffer more efficient, we try to move these pages to the free
 		list. */
 
-		buf_pool_mutex_exit();
+		//buf_pool_mutex_exit();
+		mutex_exit(&buf_pool_mutex);
 
 		buf_LRU_try_free_flushed_blocks();
 	} else {
-		buf_pool_mutex_exit();
+		//buf_pool_mutex_exit();
+		mutex_exit(&buf_pool_mutex);
 	}
 
 	if (n_iterations > 10) {
@@ -904,7 +1000,8 @@
 	ulint	new_len;
 
 	ut_a(buf_pool->LRU_old);
-	ut_ad(buf_pool_mutex_own());
+	//ut_ad(buf_pool_mutex_own());
+	ut_ad(mutex_own(&LRU_list_mutex));
 	ut_ad(buf_LRU_old_ratio >= BUF_LRU_OLD_RATIO_MIN);
 	ut_ad(buf_LRU_old_ratio <= BUF_LRU_OLD_RATIO_MAX);
 #if BUF_LRU_OLD_RATIO_MIN * BUF_LRU_OLD_MIN_LEN <= BUF_LRU_OLD_RATIO_DIV * (BUF_LRU_OLD_TOLERANCE + 5)
@@ -969,7 +1066,8 @@
 {
 	buf_page_t*	bpage;
 
-	ut_ad(buf_pool_mutex_own());
+	//ut_ad(buf_pool_mutex_own());
+	ut_ad(mutex_own(&LRU_list_mutex));
 	ut_a(UT_LIST_GET_LEN(buf_pool->LRU) == BUF_LRU_OLD_MIN_LEN);
 
 	/* We first initialize all blocks in the LRU list as old and then use
@@ -1002,13 +1100,14 @@
 	ut_ad(buf_pool);
 	ut_ad(bpage);
 	ut_ad(buf_page_in_file(bpage));
-	ut_ad(buf_pool_mutex_own());
+	//ut_ad(buf_pool_mutex_own());
+	ut_ad(mutex_own(&LRU_list_mutex));
 
 	if (buf_page_belongs_to_unzip_LRU(bpage)) {
 		buf_block_t*	block = (buf_block_t*) bpage;
 
 		ut_ad(block->in_unzip_LRU_list);
-		ut_d(block->in_unzip_LRU_list = FALSE);
+		block->in_unzip_LRU_list = FALSE;
 
 		UT_LIST_REMOVE(unzip_LRU, buf_pool->unzip_LRU, block);
 	}
@@ -1024,7 +1123,8 @@
 {
 	ut_ad(buf_pool);
 	ut_ad(bpage);
-	ut_ad(buf_pool_mutex_own());
+	//ut_ad(buf_pool_mutex_own());
+	ut_ad(mutex_own(&LRU_list_mutex));
 
 	ut_a(buf_page_in_file(bpage));
 
@@ -1099,12 +1199,13 @@
 {
 	ut_ad(buf_pool);
 	ut_ad(block);
-	ut_ad(buf_pool_mutex_own());
+	//ut_ad(buf_pool_mutex_own());
+	ut_ad(mutex_own(&LRU_list_mutex));
 
 	ut_a(buf_page_belongs_to_unzip_LRU(&block->page));
 
 	ut_ad(!block->in_unzip_LRU_list);
-	ut_d(block->in_unzip_LRU_list = TRUE);
+	block->in_unzip_LRU_list = TRUE;
 
 	if (old) {
 		UT_LIST_ADD_LAST(unzip_LRU, buf_pool->unzip_LRU, block);
@@ -1123,7 +1224,8 @@
 {
 	ut_ad(buf_pool);
 	ut_ad(bpage);
-	ut_ad(buf_pool_mutex_own());
+	//ut_ad(buf_pool_mutex_own());
+	ut_ad(mutex_own(&LRU_list_mutex));
 
 	ut_a(buf_page_in_file(bpage));
 
@@ -1172,7 +1274,8 @@
 {
 	ut_ad(buf_pool);
 	ut_ad(bpage);
-	ut_ad(buf_pool_mutex_own());
+	//ut_ad(buf_pool_mutex_own());
+	ut_ad(mutex_own(&LRU_list_mutex));
 
 	ut_a(buf_page_in_file(bpage));
 	ut_ad(!bpage->in_LRU_list);
@@ -1249,7 +1352,8 @@
 /*=====================*/
 	buf_page_t*	bpage)	/*!< in: control block */
 {
-	ut_ad(buf_pool_mutex_own());
+	//ut_ad(buf_pool_mutex_own());
+	ut_ad(mutex_own(&LRU_list_mutex));
 
 	if (bpage->old) {
 		buf_pool->stat.n_pages_made_young++;
@@ -1288,16 +1392,17 @@
 buf_LRU_free_block(
 /*===============*/
 	buf_page_t*	bpage,	/*!< in: block to be freed */
-	ibool		zip)	/*!< in: TRUE if should remove also the
+	ibool		zip,	/*!< in: TRUE if should remove also the
 				compressed page of an uncompressed page */
+	ibool		have_LRU_mutex)
 {
 	buf_page_t*	b = NULL;
 	mutex_t*	block_mutex = buf_page_get_mutex(bpage);
 
-	ut_ad(buf_pool_mutex_own());
+	//ut_ad(buf_pool_mutex_own());
 	ut_ad(mutex_own(block_mutex));
 	ut_ad(buf_page_in_file(bpage));
-	ut_ad(bpage->in_LRU_list);
+	//ut_ad(bpage->in_LRU_list);
 	ut_ad(!bpage->in_flush_list == !bpage->oldest_modification);
 #if UNIV_WORD_SIZE == 4
 	/* On 32-bit systems, there is no padding in buf_page_t.  On
@@ -1306,7 +1411,7 @@
 	UNIV_MEM_ASSERT_RW(bpage, sizeof *bpage);
 #endif
 
-	if (!buf_page_can_relocate(bpage)) {
+	if (!bpage->in_LRU_list || !block_mutex || !buf_page_can_relocate(bpage)) {
 
 		/* Do not free buffer-fixed or I/O-fixed blocks. */
 		return(FALSE);
@@ -1340,7 +1445,7 @@
 alloc:
 		b = buf_page_alloc_descriptor();
 		ut_a(b);
-		memcpy(b, bpage, sizeof *b);
+		//memcpy(b, bpage, sizeof *b);
 	}
 
 #ifdef UNIV_DEBUG
@@ -1351,6 +1456,39 @@
 	}
 #endif /* UNIV_DEBUG */
 
+	/* not to break latch order, must re-enter block_mutex */
+	mutex_exit(block_mutex);
+
+	if (!have_LRU_mutex)
+		mutex_enter(&LRU_list_mutex); /* optimistic */
+	rw_lock_x_lock(&page_hash_latch);
+	mutex_enter(block_mutex);
+
+	/* recheck states of block */
+	if (!bpage->in_LRU_list || block_mutex != buf_page_get_mutex(bpage)
+	    || !buf_page_can_relocate(bpage)) {
+not_freed:
+		if (b) {
+			buf_buddy_free(b, sizeof *b, TRUE);
+		}
+		if (!have_LRU_mutex)
+			mutex_exit(&LRU_list_mutex);
+		rw_lock_x_unlock(&page_hash_latch);
+		return(FALSE);
+	} else if (zip || !bpage->zip.data) {
+		if (bpage->oldest_modification)
+			goto not_freed;
+	} else if (bpage->oldest_modification) {
+		if (buf_page_get_state(bpage) != BUF_BLOCK_FILE_PAGE) {
+			ut_ad(buf_page_get_state(bpage) == BUF_BLOCK_ZIP_DIRTY);
+			goto not_freed;
+		}
+	}
+
+	if (b) {
+		memcpy(b, bpage, sizeof *b);
+	}
+
 	if (buf_LRU_block_remove_hashed_page(bpage, zip)
 	    != BUF_BLOCK_ZIP_FREE) {
 		ut_a(bpage->buf_fix_count == 0);
@@ -1362,6 +1500,10 @@
 
 			ut_a(!buf_page_hash_get(bpage->space, bpage->offset));
 
+			while (prev_b && !prev_b->in_LRU_list) {
+				prev_b = UT_LIST_GET_PREV(LRU, prev_b);
+			}
+
 			b->state = b->oldest_modification
 				? BUF_BLOCK_ZIP_DIRTY
 				: BUF_BLOCK_ZIP_PAGE;
@@ -1437,6 +1579,7 @@
 				buf_LRU_add_block_low(b, buf_page_is_old(b));
 			}
 
+			mutex_enter(&flush_list_mutex);
 			if (b->state == BUF_BLOCK_ZIP_PAGE) {
 #if defined UNIV_DEBUG || defined UNIV_BUF_DEBUG
 				buf_LRU_insert_zip_clean(b);
@@ -1445,6 +1588,7 @@
 				/* Relocate on buf_pool->flush_list. */
 				buf_flush_relocate_on_flush_list(bpage, b);
 			}
+			mutex_exit(&flush_list_mutex);
 
 			bpage->zip.data = NULL;
 			page_zip_set_size(&bpage->zip, 0);
@@ -1456,7 +1600,9 @@
 			b->io_fix = BUF_IO_READ;
 		}
 
-		buf_pool_mutex_exit();
+		//buf_pool_mutex_exit();
+		mutex_exit(&LRU_list_mutex);
+		rw_lock_x_unlock(&page_hash_latch);
 		mutex_exit(block_mutex);
 
 		/* Remove possible adaptive hash index on the page.
@@ -1488,7 +1634,9 @@
 				: BUF_NO_CHECKSUM_MAGIC);
 		}
 
-		buf_pool_mutex_enter();
+		//buf_pool_mutex_enter();
+		if (have_LRU_mutex)
+			mutex_enter(&LRU_list_mutex);
 		mutex_enter(block_mutex);
 
 		if (b) {
@@ -1498,13 +1646,17 @@
 			mutex_exit(&buf_pool_zip_mutex);
 		}
 
-		buf_LRU_block_free_hashed_page((buf_block_t*) bpage);
+		buf_LRU_block_free_hashed_page((buf_block_t*) bpage, FALSE);
 	} else {
 		/* The block_mutex should have been released by
 		buf_LRU_block_remove_hashed_page() when it returns
 		BUF_BLOCK_ZIP_FREE. */
 		ut_ad(block_mutex == &buf_pool_zip_mutex);
 		mutex_enter(block_mutex);
+
+		if (!have_LRU_mutex)
+			mutex_exit(&LRU_list_mutex);
+		rw_lock_x_unlock(&page_hash_latch);
 	}
 
 	return(TRUE);
@@ -1516,12 +1668,13 @@
 void
 buf_LRU_block_free_non_file_page(
 /*=============================*/
-	buf_block_t*	block)	/*!< in: block, must not contain a file page */
+	buf_block_t*	block,	/*!< in: block, must not contain a file page */
+	ibool		have_page_hash_mutex)
 {
 	void*	data;
 
 	ut_ad(block);
-	ut_ad(buf_pool_mutex_own());
+	//ut_ad(buf_pool_mutex_own());
 	ut_ad(mutex_own(&block->mutex));
 
 	switch (buf_block_get_state(block)) {
@@ -1555,15 +1708,17 @@
 	if (data) {
 		block->page.zip.data = NULL;
 		mutex_exit(&block->mutex);
-		buf_pool_mutex_exit_forbid();
-		buf_buddy_free(data, page_zip_get_size(&block->page.zip));
-		buf_pool_mutex_exit_allow();
+		//buf_pool_mutex_exit_forbid();
+		buf_buddy_free(data, page_zip_get_size(&block->page.zip), have_page_hash_mutex);
+		//buf_pool_mutex_exit_allow();
 		mutex_enter(&block->mutex);
 		page_zip_set_size(&block->page.zip, 0);
 	}
 
-	UT_LIST_ADD_FIRST(list, buf_pool->free, (&block->page));
+	mutex_enter(&free_list_mutex);
+	UT_LIST_ADD_FIRST(free, buf_pool->free, (&block->page));
 	ut_d(block->page.in_free_list = TRUE);
+	mutex_exit(&free_list_mutex);
 
 	UNIV_MEM_ASSERT_AND_FREE(block->frame, UNIV_PAGE_SIZE);
 }
@@ -1590,7 +1745,11 @@
 {
 	const buf_page_t*	hashed_bpage;
 	ut_ad(bpage);
-	ut_ad(buf_pool_mutex_own());
+	//ut_ad(buf_pool_mutex_own());
+	ut_ad(mutex_own(&LRU_list_mutex));
+#ifdef UNIV_SYNC_DEBUG
+	ut_ad(rw_lock_own(&page_hash_latch, RW_LOCK_EX));
+#endif
 	ut_ad(mutex_own(buf_page_get_mutex(bpage)));
 
 	ut_a(buf_page_get_io_fix(bpage) == BUF_IO_NONE);
@@ -1696,7 +1855,9 @@
 
 #if defined UNIV_DEBUG || defined UNIV_BUF_DEBUG
 		mutex_exit(buf_page_get_mutex(bpage));
-		buf_pool_mutex_exit();
+		//buf_pool_mutex_exit();
+		mutex_exit(&LRU_list_mutex);
+		rw_lock_x_unlock(&page_hash_latch);
 		buf_print();
 		buf_LRU_print();
 		buf_validate();
@@ -1720,14 +1881,14 @@
 		ut_a(buf_page_get_zip_size(bpage));
 
 #if defined UNIV_DEBUG || defined UNIV_BUF_DEBUG
-		UT_LIST_REMOVE(list, buf_pool->zip_clean, bpage);
+		UT_LIST_REMOVE(zip_list, buf_pool->zip_clean, bpage);
 #endif /* UNIV_DEBUG || UNIV_BUF_DEBUG */
 
 		mutex_exit(&buf_pool_zip_mutex);
-		buf_pool_mutex_exit_forbid();
+		//buf_pool_mutex_exit_forbid();
 		buf_buddy_free(bpage->zip.data,
-			       page_zip_get_size(&bpage->zip));
-		buf_pool_mutex_exit_allow();
+			       page_zip_get_size(&bpage->zip), TRUE);
+		//buf_pool_mutex_exit_allow();
 		buf_page_free_descriptor(bpage);
 		return(BUF_BLOCK_ZIP_FREE);
 
@@ -1749,9 +1910,9 @@
 			ut_ad(!bpage->in_flush_list);
 			ut_ad(!bpage->in_LRU_list);
 			mutex_exit(&((buf_block_t*) bpage)->mutex);
-			buf_pool_mutex_exit_forbid();
-			buf_buddy_free(data, page_zip_get_size(&bpage->zip));
-			buf_pool_mutex_exit_allow();
+			//buf_pool_mutex_exit_forbid();
+			buf_buddy_free(data, page_zip_get_size(&bpage->zip), TRUE);
+			//buf_pool_mutex_exit_allow();
 			mutex_enter(&((buf_block_t*) bpage)->mutex);
 			page_zip_set_size(&bpage->zip, 0);
 		}
@@ -1777,15 +1938,16 @@
 void
 buf_LRU_block_free_hashed_page(
 /*===========================*/
-	buf_block_t*	block)	/*!< in: block, must contain a file page and
+	buf_block_t*	block,	/*!< in: block, must contain a file page and
 				be in a state where it can be freed */
+	ibool		have_page_hash_mutex)
 {
-	ut_ad(buf_pool_mutex_own());
+	//ut_ad(buf_pool_mutex_own());
 	ut_ad(mutex_own(&block->mutex));
 
 	buf_block_set_state(block, BUF_BLOCK_MEMORY);
 
-	buf_LRU_block_free_non_file_page(block);
+	buf_LRU_block_free_non_file_page(block, have_page_hash_mutex);
 }
 
 /**********************************************************************//**
@@ -1811,7 +1973,8 @@
 	}
 
 	if (adjust) {
-		buf_pool_mutex_enter();
+		//buf_pool_mutex_enter();
+		mutex_enter(&LRU_list_mutex);
 
 		if (ratio != buf_LRU_old_ratio) {
 			buf_LRU_old_ratio = ratio;
@@ -1822,7 +1985,8 @@
 			}
 		}
 
-		buf_pool_mutex_exit();
+		//buf_pool_mutex_exit();
+		mutex_exit(&LRU_list_mutex);
 	} else {
 		buf_LRU_old_ratio = ratio;
 	}
@@ -1848,7 +2012,8 @@
 		goto func_exit;
 	}
 
-	buf_pool_mutex_enter();
+	//buf_pool_mutex_enter();
+	mutex_enter(&buf_pool_mutex);
 
 	/* Update the index. */
 	item = &buf_LRU_stat_arr[buf_LRU_stat_arr_ind];
@@ -1869,7 +2034,8 @@
 	/* Put current entry in the array. */
 	memcpy(item, &cur_stat, sizeof *item);
 
-	buf_pool_mutex_exit();
+	//buf_pool_mutex_exit();
+	mutex_exit(&buf_pool_mutex);
 
 func_exit:
 	/* Clear the current entry. */
@@ -1891,7 +2057,8 @@
 	ulint		new_len;
 
 	ut_ad(buf_pool);
-	buf_pool_mutex_enter();
+	//buf_pool_mutex_enter();
+	mutex_enter(&LRU_list_mutex);
 
 	if (UT_LIST_GET_LEN(buf_pool->LRU) >= BUF_LRU_OLD_MIN_LEN) {
 
@@ -1951,16 +2118,22 @@
 
 	ut_a(buf_pool->LRU_old_len == old_len);
 
-	UT_LIST_VALIDATE(list, buf_page_t, buf_pool->free,
+	mutex_exit(&LRU_list_mutex);
+	mutex_enter(&free_list_mutex);
+
+	UT_LIST_VALIDATE(free, buf_page_t, buf_pool->free,
 			 ut_ad(ut_list_node_313->in_free_list));
 
 	for (bpage = UT_LIST_GET_FIRST(buf_pool->free);
 	     bpage != NULL;
-	     bpage = UT_LIST_GET_NEXT(list, bpage)) {
+	     bpage = UT_LIST_GET_NEXT(free, bpage)) {
 
 		ut_a(buf_page_get_state(bpage) == BUF_BLOCK_NOT_USED);
 	}
 
+	mutex_exit(&free_list_mutex);
+	mutex_enter(&LRU_list_mutex);
+
 	UT_LIST_VALIDATE(unzip_LRU, buf_block_t, buf_pool->unzip_LRU,
 			 ut_ad(ut_list_node_313->in_unzip_LRU_list
 			       && ut_list_node_313->page.in_LRU_list));
@@ -1974,7 +2147,8 @@
 		ut_a(buf_page_belongs_to_unzip_LRU(&block->page));
 	}
 
-	buf_pool_mutex_exit();
+	//buf_pool_mutex_exit();
+	mutex_exit(&LRU_list_mutex);
 	return(TRUE);
 }
 #endif /* UNIV_DEBUG || UNIV_BUF_DEBUG */
@@ -1990,7 +2164,8 @@
 	const buf_page_t*	bpage;
 
 	ut_ad(buf_pool);
-	buf_pool_mutex_enter();
+	//buf_pool_mutex_enter();
+	mutex_enter(&LRU_list_mutex);
 
 	bpage = UT_LIST_GET_FIRST(buf_pool->LRU);
 
@@ -2047,6 +2222,7 @@
 		bpage = UT_LIST_GET_NEXT(LRU, bpage);
 	}
 
-	buf_pool_mutex_exit();
+	//buf_pool_mutex_exit();
+	mutex_exit(&LRU_list_mutex);
 }
 #endif /* UNIV_DEBUG_PRINT || UNIV_DEBUG || UNIV_BUF_DEBUG */
--- a/storage/innodb_plugin/buf/buf0rea.c
+++ b/storage/innodb_plugin/buf/buf0rea.c
@@ -233,18 +233,22 @@
 		high = fil_space_get_size(space);
 	}
 
-	buf_pool_mutex_enter();
+	//buf_pool_mutex_enter();
+	mutex_enter(&buf_pool_mutex);
 
 	if (buf_pool->n_pend_reads
 	    > buf_pool->curr_size / BUF_READ_AHEAD_PEND_LIMIT) {
-		buf_pool_mutex_exit();
+		//buf_pool_mutex_exit();
+		mutex_exit(&buf_pool_mutex);
 
 		return(0);
 	}
+	mutex_exit(&buf_pool_mutex);
 
 	/* Count how many blocks in the area have been recently accessed,
 	that is, reside near the start of the LRU list. */
 
+	rw_lock_s_lock(&page_hash_latch);
 	for (i = low; i < high; i++) {
 		const buf_page_t*	bpage = buf_page_hash_get(space, i);
 
@@ -256,13 +260,15 @@
 
 			if (recent_blocks >= BUF_READ_AHEAD_RANDOM_THRESHOLD) {
 
-				buf_pool_mutex_exit();
+				//buf_pool_mutex_exit();
+				rw_lock_s_unlock(&page_hash_latch);
 				goto read_ahead;
 			}
 		}
 	}
 
-	buf_pool_mutex_exit();
+	//buf_pool_mutex_exit();
+	rw_lock_s_unlock(&page_hash_latch);
 	/* Do nothing */
 	return(0);
 
@@ -460,10 +466,12 @@
 
 	tablespace_version = fil_space_get_version(space);
 
-	buf_pool_mutex_enter();
+	//buf_pool_mutex_enter();
+	mutex_enter(&buf_pool_mutex);
 
 	if (high > fil_space_get_size(space)) {
-		buf_pool_mutex_exit();
+		//buf_pool_mutex_exit();
+		mutex_exit(&buf_pool_mutex);
 		/* The area is not whole, return */
 
 		return(0);
@@ -471,10 +479,12 @@
 
 	if (buf_pool->n_pend_reads
 	    > buf_pool->curr_size / BUF_READ_AHEAD_PEND_LIMIT) {
-		buf_pool_mutex_exit();
+		//buf_pool_mutex_exit();
+		mutex_exit(&buf_pool_mutex);
 
 		return(0);
 	}
+	mutex_exit(&buf_pool_mutex);
 
 	/* Check that almost all pages in the area have been accessed; if
 	offset == low, the accesses must be in a descending order, otherwise,
@@ -493,6 +503,7 @@
 
 	fail_count = 0;
 
+	rw_lock_s_lock(&page_hash_latch);
 	for (i = low; i < high; i++) {
 		bpage = buf_page_hash_get(space, i);
 
@@ -520,7 +531,8 @@
 
 		if (fail_count > threshold) {
 			/* Too many failures: return */
-			buf_pool_mutex_exit();
+			//buf_pool_mutex_exit();
+			rw_lock_s_unlock(&page_hash_latch);
 			return(0);
 		}
 
@@ -535,7 +547,8 @@
 	bpage = buf_page_hash_get(space, offset);
 
 	if (bpage == NULL) {
-		buf_pool_mutex_exit();
+		//buf_pool_mutex_exit();
+		rw_lock_s_unlock(&page_hash_latch);
 
 		return(0);
 	}
@@ -561,7 +574,8 @@
 	pred_offset = fil_page_get_prev(frame);
 	succ_offset = fil_page_get_next(frame);
 
-	buf_pool_mutex_exit();
+	//buf_pool_mutex_exit();
+	rw_lock_s_unlock(&page_hash_latch);
 
 	if ((offset == low) && (succ_offset == offset + 1)) {
 
--- a/storage/innodb_plugin/handler/i_s.cc
+++ b/storage/innodb_plugin/handler/i_s.cc
@@ -2229,7 +2229,8 @@
 
 	RETURN_IF_INNODB_NOT_STARTED(tables->schema_table_name);
 
-	buf_pool_mutex_enter();
+	//buf_pool_mutex_enter();
+	mutex_enter(&zip_free_mutex);
 
 	for (uint x = 0; x <= BUF_BUDDY_SIZES; x++) {
 		buf_buddy_stat_t*	buddy_stat = &buf_buddy_stat[x];
@@ -2255,7 +2256,8 @@
 		}
 	}
 
-	buf_pool_mutex_exit();
+	//buf_pool_mutex_exit();
+	mutex_exit(&zip_free_mutex);
 	DBUG_RETURN(status);
 }
 
--- a/storage/innodb_plugin/handler/innodb_patch_info.h
+++ b/storage/innodb_plugin/handler/innodb_patch_info.h
@@ -33,5 +33,6 @@
 {"innodb_overwrite_relay_log_info","overwrite relay-log.info when slave recovery","Building as plugin, it is not used.","http://www.percona.com/docs/wiki/percona-xtradb:innodb_overwrite_relay_log_info"},
 {"innodb_thread_concurrency_timer_based","use InnoDB timer based concurrency throttling (backport from MySQL 5.4.0)","",""},
 {"innodb_dict_size_limit","Limit dictionary cache size","Variable innodb_dict_size_limit in bytes","http://www.percona.com/docs/wiki/percona-xtradb"},
+{"innodb_split_buf_pool_mutex","More fix of buffer_pool mutex","Spliting buf_pool_mutex and optimizing based on innodb_opt_lru_count","http://www.percona.com/docs/wiki/percona-xtradb"},
 {NULL, NULL, NULL, NULL}
 };
--- a/storage/innodb_plugin/include/buf0buddy.h
+++ b/storage/innodb_plugin/include/buf0buddy.h
@@ -46,9 +46,10 @@
 /*============*/
 	ulint	size,	/*!< in: compressed page size
 			(between PAGE_ZIP_MIN_SIZE and UNIV_PAGE_SIZE) */
-	ibool*	lru)	/*!< in: pointer to a variable that will be assigned
+	ibool*	lru,	/*!< in: pointer to a variable that will be assigned
 			TRUE if storage was allocated from the LRU list
 			and buf_pool_mutex was temporarily released */
+	ibool	have_page_hash_mutex)
 	__attribute__((malloc, nonnull));
 /**********************************************************************//**
 Release a block. */
@@ -58,7 +59,8 @@
 /*===========*/
 	void*	buf,	/*!< in: block to be freed, must not be
 			pointed to by the buffer pool */
-	ulint	size)	/*!< in: block size, up to UNIV_PAGE_SIZE */
+	ulint	size,	/*!< in: block size, up to UNIV_PAGE_SIZE */
+	ibool	have_page_hash_mutex)
 	__attribute__((nonnull));
 
 /** Statistics of buddy blocks of a given size. */
--- a/storage/innodb_plugin/include/buf0buddy.ic
+++ b/storage/innodb_plugin/include/buf0buddy.ic
@@ -44,9 +44,10 @@
 /*================*/
 	ulint	i,	/*!< in: index of buf_pool->zip_free[],
 			or BUF_BUDDY_SIZES */
-	ibool*	lru)	/*!< in: pointer to a variable that will be assigned
+	ibool*	lru,	/*!< in: pointer to a variable that will be assigned
 			TRUE if storage was allocated from the LRU list
 			and buf_pool_mutex was temporarily released */
+	ibool	have_page_hash_mutex)
 	__attribute__((malloc, nonnull));
 
 /**********************************************************************//**
@@ -57,8 +58,9 @@
 /*===============*/
 	void*	buf,	/*!< in: block to be freed, must not be
 			pointed to by the buffer pool */
-	ulint	i)	/*!< in: index of buf_pool->zip_free[],
+	ulint	i,	/*!< in: index of buf_pool->zip_free[],
 			or BUF_BUDDY_SIZES */
+	ibool	have_page_hash_mutex)
 	__attribute__((nonnull));
 
 /**********************************************************************//**
@@ -94,16 +96,17 @@
 /*============*/
 	ulint	size,	/*!< in: compressed page size
 			(between PAGE_ZIP_MIN_SIZE and UNIV_PAGE_SIZE) */
-	ibool*	lru)	/*!< in: pointer to a variable that will be assigned
+	ibool*	lru,	/*!< in: pointer to a variable that will be assigned
 			TRUE if storage was allocated from the LRU list
 			and buf_pool_mutex was temporarily released */
+	ibool	have_page_hash_mutex)
 {
-	ut_ad(buf_pool_mutex_own());
+	//ut_ad(buf_pool_mutex_own());
 	ut_ad(ut_is_2pow(size));
 	ut_ad(size >= PAGE_ZIP_MIN_SIZE);
 	ut_ad(size <= UNIV_PAGE_SIZE);
 
-	return((byte*) buf_buddy_alloc_low(buf_buddy_get_slot(size), lru));
+	return((byte*) buf_buddy_alloc_low(buf_buddy_get_slot(size), lru, have_page_hash_mutex));
 }
 
 /**********************************************************************//**
@@ -114,14 +117,27 @@
 /*===========*/
 	void*	buf,	/*!< in: block to be freed, must not be
 			pointed to by the buffer pool */
-	ulint	size)	/*!< in: block size, up to UNIV_PAGE_SIZE */
+	ulint	size,	/*!< in: block size, up to UNIV_PAGE_SIZE */
+	ibool	have_page_hash_mutex)
 {
-	ut_ad(buf_pool_mutex_own());
+	//ut_ad(buf_pool_mutex_own());
 	ut_ad(ut_is_2pow(size));
 	ut_ad(size >= PAGE_ZIP_MIN_SIZE);
 	ut_ad(size <= UNIV_PAGE_SIZE);
 
-	buf_buddy_free_low(buf, buf_buddy_get_slot(size));
+	if (!have_page_hash_mutex) {
+		mutex_enter(&LRU_list_mutex);
+		rw_lock_x_lock(&page_hash_latch);
+	}
+
+	mutex_enter(&zip_free_mutex);
+	buf_buddy_free_low(buf, buf_buddy_get_slot(size), TRUE);
+	mutex_exit(&zip_free_mutex);
+
+	if (!have_page_hash_mutex) {
+		mutex_exit(&LRU_list_mutex);
+		rw_lock_x_unlock(&page_hash_latch);
+	}
 }
 
 #ifdef UNIV_MATERIALIZE
--- a/storage/innodb_plugin/include/buf0buf.h
+++ b/storage/innodb_plugin/include/buf0buf.h
@@ -761,6 +761,15 @@
 	const buf_page_t*	bpage)	/*!< in: pointer to control block */
 	__attribute__((pure));
 
+/*************************************************************************
+Gets the mutex of a block and enter the mutex with consistency. */
+UNIV_INLINE
+mutex_t*
+buf_page_get_mutex_enter(
+/*=========================*/
+	const buf_page_t*	bpage)	/*!< in: pointer to control block */
+	__attribute__((pure));
+
 /*********************************************************************//**
 Get the flush type of a page.
 @return	flush type */
@@ -1114,7 +1123,7 @@
 	All these are protected by buf_pool_mutex. */
 	/* @{ */
 
-	UT_LIST_NODE_T(buf_page_t) list;
+	/* UT_LIST_NODE_T(buf_page_t) list; */
 					/*!< based on state, this is a
 					list node, protected only by
 					buf_pool_mutex, in one of the
@@ -1134,6 +1143,10 @@
 					BUF_BLOCK_REMOVE_HASH or
 					BUF_BLOCK_READY_IN_USE. */
 
+	/* resplit for optimistic use */
+	UT_LIST_NODE_T(buf_page_t) free;
+	UT_LIST_NODE_T(buf_page_t) flush_list;
+	UT_LIST_NODE_T(buf_page_t) zip_list; /* zip_clean or zip_free[] */
 #ifdef UNIV_DEBUG
 	ibool		in_flush_list;	/*!< TRUE if in buf_pool->flush_list;
 					when buf_pool_mutex is free, the
@@ -1214,11 +1227,11 @@
 					a block is in the unzip_LRU list
 					if page.state == BUF_BLOCK_FILE_PAGE
 					and page.zip.data != NULL */
-#ifdef UNIV_DEBUG
+//#ifdef UNIV_DEBUG
 	ibool		in_unzip_LRU_list;/*!< TRUE if the page is in the
 					decompressed LRU list;
 					used in debugging */
-#endif /* UNIV_DEBUG */
+//#endif /* UNIV_DEBUG */
 	mutex_t		mutex;		/*!< mutex protecting this block:
 					state (also protected by the buffer
 					pool mutex), io_fix, buf_fix_count,
@@ -1498,6 +1511,12 @@
 /** mutex protecting the buffer pool struct and control blocks, except the
 read-write lock in them */
 extern mutex_t	buf_pool_mutex;
+extern mutex_t	LRU_list_mutex;
+extern mutex_t	flush_list_mutex;
+extern rw_lock_t	page_hash_latch;
+extern mutex_t	free_list_mutex;
+extern mutex_t	zip_free_mutex;
+extern mutex_t	zip_hash_mutex;
 /** mutex protecting the control blocks of compressed-only pages
 (of type buf_page_t, not buf_block_t) */
 extern mutex_t	buf_pool_zip_mutex;
@@ -1509,8 +1528,8 @@
 /** Test if buf_pool_mutex is owned. */
 #define buf_pool_mutex_own() mutex_own(&buf_pool_mutex)
 /** Acquire the buffer pool mutex. */
+/* the buf_pool_mutex is changed the latch order */
 #define buf_pool_mutex_enter() do {		\
-	ut_ad(!mutex_own(&buf_pool_zip_mutex));	\
 	mutex_enter(&buf_pool_mutex);		\
 } while (0)
 
--- a/storage/innodb_plugin/include/buf0buf.ic
+++ b/storage/innodb_plugin/include/buf0buf.ic
@@ -137,7 +137,9 @@
 	buf_page_t*	bpage;
 	ib_uint64_t	lsn;
 
-	buf_pool_mutex_enter();
+try_again:
+	//buf_pool_mutex_enter();
+	mutex_enter(&flush_list_mutex);
 
 	bpage = UT_LIST_GET_LAST(buf_pool->flush_list);
 
@@ -146,9 +148,14 @@
 	} else {
 		ut_ad(bpage->in_flush_list);
 		lsn = bpage->oldest_modification;
+		if (lsn == 0) {
+			mutex_exit(&flush_list_mutex);
+			goto try_again;
+		}
 	}
 
-	buf_pool_mutex_exit();
+	//buf_pool_mutex_exit();
+	mutex_exit(&flush_list_mutex);
 
 	/* The returned answer may be out of date: the flush_list can
 	change after the mutex has been released. */
@@ -268,7 +275,7 @@
 	case BUF_BLOCK_ZIP_FREE:
 		/* This is a free page in buf_pool->zip_free[].
 		Such pages should only be accessed by the buddy allocator. */
-		ut_error;
+		/* ut_error; */ /* optimistic */
 		break;
 	case BUF_BLOCK_ZIP_PAGE:
 	case BUF_BLOCK_ZIP_DIRTY:
@@ -311,7 +318,7 @@
 {
 	switch (buf_page_get_state(bpage)) {
 	case BUF_BLOCK_ZIP_FREE:
-		ut_error;
+		/* ut_error; */ /* optimistic */
 		return(NULL);
 	case BUF_BLOCK_ZIP_PAGE:
 	case BUF_BLOCK_ZIP_DIRTY:
@@ -321,6 +328,28 @@
 	}
 }
 
+/*************************************************************************
+Gets the mutex of a block and enter the mutex with consistency. */
+UNIV_INLINE
+mutex_t*
+buf_page_get_mutex_enter(
+/*=========================*/
+	const buf_page_t*	bpage)	/*!< in: pointer to control block */
+{
+	mutex_t*	block_mutex;
+
+	while(1) {
+		block_mutex = buf_page_get_mutex(bpage);
+		if (!block_mutex)
+			return block_mutex;
+
+		mutex_enter(block_mutex);
+		if (block_mutex == buf_page_get_mutex(bpage))
+			return block_mutex;
+		mutex_exit(block_mutex);
+	}
+}
+
 /*********************************************************************//**
 Get the flush type of a page.
 @return	flush type */
@@ -416,7 +445,7 @@
 	buf_page_t*	bpage,	/*!< in/out: control block */
 	enum buf_io_fix	io_fix)	/*!< in: io_fix state */
 {
-	ut_ad(buf_pool_mutex_own());
+	//ut_ad(buf_pool_mutex_own());
 	ut_ad(mutex_own(buf_page_get_mutex(bpage)));
 
 	bpage->io_fix = io_fix;
@@ -444,12 +473,13 @@
 /*==================*/
 	const buf_page_t*	bpage)	/*!< control block being relocated */
 {
-	ut_ad(buf_pool_mutex_own());
+	//ut_ad(buf_pool_mutex_own());
 	ut_ad(mutex_own(buf_page_get_mutex(bpage)));
 	ut_ad(buf_page_in_file(bpage));
-	ut_ad(bpage->in_LRU_list);
+	/* optimistic */
+	//ut_ad(bpage->in_LRU_list);
 
-	return(buf_page_get_io_fix(bpage) == BUF_IO_NONE
+	return(bpage->in_LRU_list && bpage->io_fix == BUF_IO_NONE
 	       && bpage->buf_fix_count == 0);
 }
 
@@ -463,7 +493,7 @@
 	const buf_page_t*	bpage)	/*!< in: control block */
 {
 	ut_ad(buf_page_in_file(bpage));
-	ut_ad(buf_pool_mutex_own());
+	//ut_ad(buf_pool_mutex_own()); /* This is used in optimistic */
 
 	return(bpage->old);
 }
@@ -478,7 +508,8 @@
 	ibool		old)	/*!< in: old */
 {
 	ut_a(buf_page_in_file(bpage));
-	ut_ad(buf_pool_mutex_own());
+	//ut_ad(buf_pool_mutex_own());
+	ut_ad(mutex_own(&LRU_list_mutex));
 	ut_ad(bpage->in_LRU_list);
 
 #ifdef UNIV_LRU_DEBUG
@@ -525,7 +556,8 @@
 	ulint		time_ms)	/*!< in: ut_time_ms() */
 {
 	ut_a(buf_page_in_file(bpage));
-	ut_ad(buf_pool_mutex_own());
+	//ut_ad(buf_pool_mutex_own());
+	ut_ad(mutex_own(buf_page_get_mutex(bpage)));
 
 	if (!bpage->access_time) {
 		/* Make this the time of the first access. */
@@ -784,17 +816,17 @@
 /*===========*/
 	buf_block_t*	block)	/*!< in, own: block to be freed */
 {
-	buf_pool_mutex_enter();
+	//buf_pool_mutex_enter();
 
 	mutex_enter(&block->mutex);
 
 	ut_a(buf_block_get_state(block) != BUF_BLOCK_FILE_PAGE);
 
-	buf_LRU_block_free_non_file_page(block);
+	buf_LRU_block_free_non_file_page(block, FALSE);
 
 	mutex_exit(&block->mutex);
 
-	buf_pool_mutex_exit();
+	//buf_pool_mutex_exit();
 }
 #endif /* !UNIV_HOTBACKUP */
 
@@ -842,17 +874,17 @@
 					page frame */
 {
 	ib_uint64_t	lsn;
-	mutex_t*	block_mutex = buf_page_get_mutex(bpage);
+	mutex_t*	block_mutex = buf_page_get_mutex_enter(bpage);
 
-	mutex_enter(block_mutex);
-
-	if (buf_page_in_file(bpage)) {
+	if (block_mutex && buf_page_in_file(bpage)) {
 		lsn = bpage->newest_modification;
 	} else {
 		lsn = 0;
 	}
 
-	mutex_exit(block_mutex);
+	if (block_mutex) {
+		mutex_exit(block_mutex);
+	}
 
 	return(lsn);
 }
@@ -868,7 +900,7 @@
 	buf_block_t*	block)	/*!< in: block */
 {
 #ifdef UNIV_SYNC_DEBUG
-	ut_ad((buf_pool_mutex_own()
+	ut_ad((mutex_own(&LRU_list_mutex)
 	       && (block->page.buf_fix_count == 0))
 	      || rw_lock_own(&(block->lock), RW_LOCK_EXCLUSIVE));
 #endif /* UNIV_SYNC_DEBUG */
@@ -947,7 +979,11 @@
 	ulint		fold;
 
 	ut_ad(buf_pool);
-	ut_ad(buf_pool_mutex_own());
+	//ut_ad(buf_pool_mutex_own());
+#ifdef UNIV_SYNC_DEBUG
+	ut_ad(rw_lock_own(&page_hash_latch, RW_LOCK_EX)
+	      || rw_lock_own(&page_hash_latch, RW_LOCK_SHARED));
+#endif
 
 	/* Look for the page in the hash table */
 
@@ -1002,11 +1038,13 @@
 {
 	const buf_page_t*	bpage;
 
-	buf_pool_mutex_enter();
+	//buf_pool_mutex_enter();
+	rw_lock_s_lock(&page_hash_latch);
 
 	bpage = buf_page_hash_get(space, offset);
 
-	buf_pool_mutex_exit();
+	//buf_pool_mutex_exit();
+	rw_lock_s_unlock(&page_hash_latch);
 
 	return(bpage != NULL);
 }
@@ -1061,18 +1099,21 @@
 	buf_block_t*	block,		/*!< in: buffer block */
 	ulint		rw_latch,	/*!< in: RW_S_LATCH, RW_X_LATCH,
 					RW_NO_LATCH */
-	mtr_t*		mtr)		/*!< in: mtr */
+	mtr_t*		mtr __attribute__((unused)))		/*!< in: mtr */
 {
 	ut_ad(block);
 
 	ut_a(buf_block_get_state(block) == BUF_BLOCK_FILE_PAGE);
 	ut_a(block->page.buf_fix_count > 0);
 
+	/* buf_flush_note_modification() should be called before this function. */
+/*
 	if (rw_latch == RW_X_LATCH && mtr->modifications) {
 		buf_pool_mutex_enter();
 		buf_flush_note_modification(block, mtr);
 		buf_pool_mutex_exit();
 	}
+*/
 
 	mutex_enter(&block->mutex);
 
--- a/storage/innodb_plugin/include/buf0flu.ic
+++ b/storage/innodb_plugin/include/buf0flu.ic
@@ -55,13 +55,23 @@
 	buf_block_t*	block,	/*!< in: block which is modified */
 	mtr_t*		mtr)	/*!< in: mtr */
 {
+	ibool	use_LRU_mutex = FALSE;
+
+	if (UT_LIST_GET_LEN(buf_pool->unzip_LRU))
+		use_LRU_mutex = TRUE;
+
+	if (use_LRU_mutex)
+		mutex_enter(&LRU_list_mutex);
+
+	mutex_enter(&block->mutex);
+
 	ut_ad(block);
 	ut_ad(buf_block_get_state(block) == BUF_BLOCK_FILE_PAGE);
 	ut_ad(block->page.buf_fix_count > 0);
 #ifdef UNIV_SYNC_DEBUG
 	ut_ad(rw_lock_own(&(block->lock), RW_LOCK_EX));
 #endif /* UNIV_SYNC_DEBUG */
-	ut_ad(buf_pool_mutex_own());
+	//ut_ad(buf_pool_mutex_own());
 
 	ut_ad(mtr->start_lsn != 0);
 	ut_ad(mtr->modifications);
@@ -70,16 +80,23 @@
 	block->page.newest_modification = mtr->end_lsn;
 
 	if (!block->page.oldest_modification) {
+		mutex_enter(&flush_list_mutex);
 
 		block->page.oldest_modification = mtr->start_lsn;
 		ut_ad(block->page.oldest_modification != 0);
 
 		buf_flush_insert_into_flush_list(block);
+		mutex_exit(&flush_list_mutex);
 	} else {
 		ut_ad(block->page.oldest_modification <= mtr->start_lsn);
 	}
 
+	mutex_exit(&block->mutex);
+
 	++srv_buf_pool_write_requests;
+
+	if (use_LRU_mutex)
+		mutex_exit(&LRU_list_mutex);
 }
 
 /********************************************************************//**
@@ -94,6 +111,16 @@
 	ib_uint64_t	end_lsn)	/*!< in: end lsn of the last mtr in the
 					set of mtr's */
 {
+	ibool	use_LRU_mutex = FALSE;
+
+	if(UT_LIST_GET_LEN(buf_pool->unzip_LRU))
+		use_LRU_mutex = TRUE;
+
+	if (use_LRU_mutex)
+		mutex_enter(&LRU_list_mutex);
+
+	mutex_enter(&(block->mutex));
+
 	ut_ad(block);
 	ut_ad(buf_block_get_state(block) == BUF_BLOCK_FILE_PAGE);
 	ut_ad(block->page.buf_fix_count > 0);
@@ -101,23 +128,28 @@
 	ut_ad(rw_lock_own(&(block->lock), RW_LOCK_EX));
 #endif /* UNIV_SYNC_DEBUG */
 
-	buf_pool_mutex_enter();
+	//buf_pool_mutex_enter();
 
 	ut_ad(block->page.newest_modification <= end_lsn);
 
 	block->page.newest_modification = end_lsn;
 
 	if (!block->page.oldest_modification) {
+		mutex_enter(&flush_list_mutex);
 
 		block->page.oldest_modification = start_lsn;
 
 		ut_ad(block->page.oldest_modification != 0);
 
 		buf_flush_insert_sorted_into_flush_list(block);
+		mutex_exit(&flush_list_mutex);
 	} else {
 		ut_ad(block->page.oldest_modification <= start_lsn);
 	}
 
-	buf_pool_mutex_exit();
+	//buf_pool_mutex_exit();
+	if (use_LRU_mutex)
+		mutex_exit(&LRU_list_mutex);
+	mutex_exit(&(block->mutex));
 }
 #endif /* !UNIV_HOTBACKUP */
--- a/storage/innodb_plugin/include/buf0lru.h
+++ b/storage/innodb_plugin/include/buf0lru.h
@@ -99,8 +99,9 @@
 buf_LRU_free_block(
 /*===============*/
 	buf_page_t*	bpage,	/*!< in: block to be freed */
-	ibool		zip)	/*!< in: TRUE if should remove also the
+	ibool		zip,	/*!< in: TRUE if should remove also the
 				compressed page of an uncompressed page */
+	ibool		have_LRU_mutex)
 	__attribute__((nonnull));
 /******************************************************************//**
 Try to free a replaceable block.
@@ -142,7 +143,8 @@
 void
 buf_LRU_block_free_non_file_page(
 /*=============================*/
-	buf_block_t*	block);	/*!< in: block, must not contain a file page */
+	buf_block_t*	block,	/*!< in: block, must not contain a file page */
+	ibool		have_page_hash_mutex);
 /******************************************************************//**
 Adds a block to the LRU list. */
 UNIV_INTERN
--- a/storage/innodb_plugin/include/sync0sync.h
+++ b/storage/innodb_plugin/include/sync0sync.h
@@ -489,8 +489,14 @@
 					SYNC_SEARCH_SYS, as memory allocation
 					can call routines there! Otherwise
 					the level is SYNC_MEM_HASH. */
+#define SYNC_BUF_LRU_LIST	157
+#define SYNC_BUF_PAGE_HASH	156
+#define	SYNC_BUF_BLOCK		155
+#define SYNC_BUF_FREE_LIST	153
+#define SYNC_BUF_ZIP_FREE	152
+#define SYNC_BUF_ZIP_HASH	151
 #define	SYNC_BUF_POOL		150
-#define	SYNC_BUF_BLOCK		149
+#define SYNC_BUF_FLUSH_LIST	149
 #define SYNC_DOUBLEWRITE	140
 #define	SYNC_ANY_LATCH		135
 #define SYNC_THR_LOCAL		133
@@ -521,7 +527,7 @@
 		os_fast_mutex;	/*!< We use this OS mutex in place of lock_word
 				when atomic operations are not enabled */
 #endif
-	ulint	waiters;	/*!< This ulint is set to 1 if there are (or
+	volatile ulint	waiters;	/*!< This ulint is set to 1 if there are (or
 				may be) threads waiting in the global wait
 				array for this mutex to be released.
 				Otherwise, this is 0. */
--- a/storage/innodb_plugin/mtr/mtr0mtr.c
+++ b/storage/innodb_plugin/mtr/mtr0mtr.c
@@ -33,6 +33,7 @@
 #include "page0types.h"
 #include "mtr0log.h"
 #include "log0log.h"
+#include "buf0flu.h"
 
 #ifndef UNIV_HOTBACKUP
 # include "log0recv.h"
@@ -105,6 +106,38 @@
 	}
 }
 
+UNIV_INLINE
+void
+mtr_memo_note_modification_all(
+/*===========================*/
+	mtr_t*	mtr)	/* in: mtr */
+{
+	mtr_memo_slot_t* slot;
+	dyn_array_t*	memo;
+	ulint		offset;
+
+	ut_ad(mtr);
+	ut_ad(mtr->magic_n == MTR_MAGIC_N);
+	ut_ad(mtr->state == MTR_COMMITTING); /* Currently only used in
+					     commit */
+	ut_ad(mtr->modifications);
+
+	memo = &(mtr->memo);
+
+	offset = dyn_array_get_data_size(memo);
+
+	while (offset > 0) {
+		offset -= sizeof(mtr_memo_slot_t);
+		slot = dyn_array_get_element(memo, offset);
+
+		if (UNIV_LIKELY(slot->object != NULL) &&
+		    slot->type == MTR_MEMO_PAGE_X_FIX) {
+			buf_flush_note_modification(
+				(buf_block_t*)slot->object, mtr);
+		}
+	}
+}
+
 /************************************************************//**
 Writes the contents of a mini-transaction log, if any, to the database log. */
 static
@@ -188,6 +221,8 @@
 
 	if (write_log) {
 		mtr_log_reserve_and_write(mtr);
+
+		mtr_memo_note_modification_all(mtr);
 	}
 
 	/* We first update the modification info to buffer pages, and only
@@ -198,11 +233,13 @@
 	required when we insert modified buffer pages in to the flush list
 	which must be sorted on oldest_modification. */
 
-	mtr_memo_pop_all(mtr);
-
 	if (write_log) {
 		log_release();
 	}
+
+	/* All unlocking has been moved here, after log_sys mutex release. */
+	mtr_memo_pop_all(mtr);
+
 #endif /* !UNIV_HOTBACKUP */
 
 	ut_d(mtr->state = MTR_COMMITTED);
@@ -239,6 +276,12 @@
 		slot = dyn_array_get_element(memo, offset);
 
 		if ((object == slot->object) && (type == slot->type)) {
+			if (mtr->modifications &&
+			    UNIV_LIKELY(slot->object != NULL) &&
+			    slot->type == MTR_MEMO_PAGE_X_FIX) {
+				buf_flush_note_modification(
+					(buf_block_t*)slot->object, mtr);
+			}
 
 			mtr_memo_slot_release(mtr, slot);
 
--- a/storage/innodb_plugin/srv/srv0srv.c
+++ b/storage/innodb_plugin/srv/srv0srv.c
@@ -2873,7 +2873,7 @@
 
 					mutex_exit(&(log_sys->mutex));
 
-					buf_pool_mutex_enter();
+					mutex_enter(&flush_list_mutex);
 
 					level = 0;
 					bpage = UT_LIST_GET_FIRST(buf_pool->flush_list);
@@ -2895,7 +2895,7 @@
 						bpl = 0;
 					}
 
-					buf_pool_mutex_exit();
+					mutex_exit(&flush_list_mutex);
 
 					if (!srv_use_doublewrite_buf) {
 						/* flush is faster than when doublewrite */
--- a/storage/innodb_plugin/sync/sync0sync.c
+++ b/storage/innodb_plugin/sync/sync0sync.c
@@ -254,7 +254,7 @@
 	mutex->lock_word = 0;
 #endif
 	mutex->event = os_event_create(NULL);
-	mutex_set_waiters(mutex, 0);
+	mutex->waiters = 0;
 #ifdef UNIV_DEBUG
 	mutex->magic_n = MUTEX_MAGIC_N;
 #endif /* UNIV_DEBUG */
@@ -432,6 +432,15 @@
 	mutex_t*	mutex,	/*!< in: mutex */
 	ulint		n)	/*!< in: value to set */
 {
+#ifdef INNODB_RW_LOCKS_USE_ATOMICS
+	ut_ad(mutex);
+
+	if (n) {
+		os_compare_and_swap_ulint(&mutex->waiters, 0, 1);
+	} else {
+		os_compare_and_swap_ulint(&mutex->waiters, 1, 0);
+	}
+#else
 	volatile ulint*	ptr;		/* declared volatile to ensure that
 					the value is stored to memory */
 	ut_ad(mutex);
@@ -440,6 +449,7 @@
 
 	*ptr = n;		/* Here we assume that the write of a single
 				word in memory is atomic */
+#endif
 }
 
 /******************************************************************//**
@@ -1158,6 +1168,12 @@
 	case SYNC_TRX_SYS_HEADER:
 	case SYNC_FILE_FORMAT_TAG:
 	case SYNC_DOUBLEWRITE:
+	case SYNC_BUF_LRU_LIST:
+	case SYNC_BUF_FLUSH_LIST:
+	case SYNC_BUF_PAGE_HASH:
+	case SYNC_BUF_FREE_LIST:
+	case SYNC_BUF_ZIP_FREE:
+	case SYNC_BUF_ZIP_HASH:
 	case SYNC_BUF_POOL:
 	case SYNC_SEARCH_SYS:
 	case SYNC_SEARCH_SYS_CONF:
@@ -1186,7 +1202,7 @@
 		buffer block (block->mutex or buf_pool_zip_mutex). */
 		if (!sync_thread_levels_g(array, level, FALSE)) {
 			ut_a(sync_thread_levels_g(array, level - 1, TRUE));
-			ut_a(sync_thread_levels_contain(array, SYNC_BUF_POOL));
+			ut_a(sync_thread_levels_contain(array, SYNC_BUF_LRU_LIST));
 		}
 		break;
 	case SYNC_REC_LOCK:
